{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "40576186",
      "metadata": {},
      "source": [
        "The structure of this notebook goes as follows:\n",
        "1) Load in fastq.gz files, assign relevant information, and cut/trim the raw sequences\n",
        "2) Inspecting the nature and quality of all your samples and decide parameters of further analysis\n",
        "3) Assign taxa with reference classifier, then calculate core diversity metrics\n",
        "4) Visualise alpha/beta diversity\n",
        "5) Calculate permanova/betadisper (which helps explain the result of diversity metrics)\n",
        "6) Identify differential taxa (specific microbes that differ in subsets of your samples)\n",
        "7) Create cladogram"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2c9539a",
      "metadata": {},
      "source": [
        "Section 1 we must create  a \"manifest.tsv\" (which provides paths to the actual sequence files) and a \"metadata.tsv\" (which provides details to the experiment which gives context to each sample in analysis). These two files will guide the entire analysis pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f86f23fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import all necessary packages\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import biom\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "from matplotlib.patches import Ellipse\n",
        "import glob\n",
        "import csv\n",
        "import json\n",
        "import qiime2\n",
        "import seaborn as sns\n",
        "from skbio.stats.ordination import OrdinationResults\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "aaf8b364",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Manifest written to: /home/patwuch/projects/microbiome/experiments/莊/manifest.tsv\n",
            "Samples included: 9\n",
            "<bound method NDFrame.head of    sampleid                          forward-absolute-filepath  \\\n",
            "0      C1_C  /home/patwuch/projects/microbiome/experiments/...   \n",
            "1  E2_1_ACC  /home/patwuch/projects/microbiome/experiments/...   \n",
            "2  E2_2_ACC  /home/patwuch/projects/microbiome/experiments/...   \n",
            "3  E3_1_ACC  /home/patwuch/projects/microbiome/experiments/...   \n",
            "4  E3_1_OVA  /home/patwuch/projects/microbiome/experiments/...   \n",
            "5  E4_2_OVA  /home/patwuch/projects/microbiome/experiments/...   \n",
            "6    E4_4_C  /home/patwuch/projects/microbiome/experiments/...   \n",
            "7    E5_3_C  /home/patwuch/projects/microbiome/experiments/...   \n",
            "8    O5_OVA  /home/patwuch/projects/microbiome/experiments/...   \n",
            "\n",
            "                           reverse-absolute-filepath  \n",
            "0  /home/patwuch/projects/microbiome/experiments/...  \n",
            "1  /home/patwuch/projects/microbiome/experiments/...  \n",
            "2  /home/patwuch/projects/microbiome/experiments/...  \n",
            "3  /home/patwuch/projects/microbiome/experiments/...  \n",
            "4  /home/patwuch/projects/microbiome/experiments/...  \n",
            "5  /home/patwuch/projects/microbiome/experiments/...  \n",
            "6  /home/patwuch/projects/microbiome/experiments/...  \n",
            "7  /home/patwuch/projects/microbiome/experiments/...  \n",
            "8  /home/patwuch/projects/microbiome/experiments/...  >\n"
          ]
        }
      ],
      "source": [
        "\n",
        "'''This cell creates a manifest file for QIIME2 from a directory of FASTQ files. \n",
        "Alternatively, you can create the manifest file manually if you have specific naming conventions.'''\n",
        "\n",
        "# Get notebook directory\n",
        "project_dir = Path(os.getcwd())\n",
        "\n",
        "# Define input/output dirs\n",
        "raw_dir = project_dir / \"raw\"\n",
        "qiime_dir = project_dir / 'qiime'\n",
        "manifest_file = project_dir / \"manifest.tsv\"\n",
        "\n",
        "# Recursively list all FASTQ files\n",
        "fastqs = sorted(raw_dir.rglob(\"*.fq.gz\"))\n",
        "\n",
        "if not fastqs:\n",
        "    raise FileNotFoundError(f\"No FASTQ files found in {raw_dir}\")\n",
        "# Helper: normalize sample names\n",
        "# An advice: \n",
        "# Name the column that stores your sample IDs 'sampleid', as R packages sometimes\n",
        "# have trouble parsing underscores and hyphens\n",
        "# Also, if there are blank spaces in a sample ID, it might cause problems in some downstream tools\n",
        "# If possibile replace them with underscores\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "def extract_sample_name(fname: Path) -> str:\n",
        "    \"\"\"\n",
        "    Remove everything from the first underscore onwards,\n",
        "    strip extensions, truncate at the first space,\n",
        "    and replace hyphens or spaces with underscores.\n",
        "    \"\"\"\n",
        "    name = fname.stem  # removes .gz or other suffixes if present\n",
        "    if name.endswith(\".fastq\"):\n",
        "        name = name[:-6]\n",
        "    elif name.endswith(\".fq\"):\n",
        "        name = name[:-3]\n",
        "\n",
        "    # Remove everything after the first underscore\n",
        "    name = name.split(\"_\")[0]\n",
        "\n",
        "    # Replace hyphens or spaces with underscores\n",
        "    name = re.sub(r\"[-\\s]\", \"_\", name)\n",
        "\n",
        "    return name\n",
        "\n",
        "\n",
        "# Group by sample name\n",
        "samples = {}\n",
        "for f in fastqs:\n",
        "    sample = extract_sample_name(f)\n",
        "    if sample not in samples:\n",
        "        samples[sample] = {\"R1\": None, \"R2\": None}\n",
        "\n",
        "    if re.search(r\"(R1|_1)\\.f(ast)?q\\.gz$\", f.name):\n",
        "        samples[sample][\"R1\"] = f.resolve()\n",
        "    elif re.search(r\"(R2|_2)\\.f(ast)?q\\.gz$\", f.name):\n",
        "        samples[sample][\"R2\"] = f.resolve()\n",
        "\n",
        "# Build manifest DataFrame\n",
        "records = []\n",
        "for sample, files in samples.items():\n",
        "    if files[\"R1\"] and files[\"R2\"]:\n",
        "        records.append({\n",
        "            \"sampleid\": sample,\n",
        "            \"forward-absolute-filepath\": str(files[\"R1\"]),\n",
        "            \"reverse-absolute-filepath\": str(files[\"R2\"]),\n",
        "        })\n",
        "    else:\n",
        "        print(f\"⚠️ Skipping {sample}: missing R1 or R2\")\n",
        "\n",
        "\n",
        "manifest = pd.DataFrame(records)\n",
        "\n",
        "# Save manifest\n",
        "manifest.to_csv(manifest_file, sep=\"\\t\", index=False)\n",
        "\n",
        "print(f\"✅ Manifest written to: {manifest_file.resolve()}\")\n",
        "print(f\"Samples included: {len(manifest)}\")\n",
        "print(manifest.head)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dbb1e9c",
      "metadata": {},
      "source": [
        "Section 2 we start actually working with our sequences. We will inspect quality, denoise, truncate, and inspect again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mImported manifest.tsv as PairedEndFastqManifestPhred33V2 to qiime/demux.qza\u001b[0m\n",
            "\u001b[?25h\u001b[0m"
          ]
        }
      ],
      "source": [
        "# This imports the fastq files and creates a QIIME2 artifact\n",
        "!mkdir -p qiime\n",
        "# Select the manifest \n",
        "!qiime tools import \\\n",
        "  --type 'SampleData[PairedEndSequencesWithQuality]' \\\n",
        "  --input-format PairedEndFastqManifestPhred33V2 \\\n",
        "  --input-path \"manifest.tsv\" \\\n",
        "  --output-path \"qiime/demux.qza\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fd4e685c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved Visualization to: qiime/demux.qzv\u001b[0m\n",
            "\u001b[?25h\u001b[0m"
          ]
        }
      ],
      "source": [
        "# This creates a qiime2 visualisation artefact with which you can check on QIIME2 View the quality of the reads\n",
        "# Based on the QC plots, you can decide the length at which to trim the reads in the next step\n",
        "!qiime demux summarize \\\n",
        "    --i-data \"qiime/demux.qza\" \\\n",
        "    --o-visualization \"qiime/demux.qzv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "315e4e72",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved FeatureTable[Frequency] to: qiime/table.qza\u001b[0m\n",
            "\u001b[32mSaved FeatureData[Sequence] to: qiime/rep-seqs.qza\u001b[0m\n",
            "\u001b[32mSaved SampleData[DADA2Stats] to: qiime/stats.qza\u001b[0m\n",
            "\u001b[?25h\u001b[0m"
          ]
        }
      ],
      "source": [
        "# DADA2 is a popular denoising algorithm that corrects amplicon errors while also removing chimeras\n",
        "# It will return artefacts which can be converted to visualisation to see if we trimmed appropriately\n",
        "!qiime dada2 denoise-paired \\\n",
        "    --i-demultiplexed-seqs \"qiime/demux.qza\" \\\n",
        "    --p-trim-left-f 10 \\\n",
        "    --p-trim-left-r 10 \\\n",
        "    --p-trunc-len-f 260 \\\n",
        "    --p-trunc-len-r 220 \\\n",
        "    --o-table \"qiime/table.qza\" \\\n",
        "    --o-representative-sequences \"qiime/rep-seqs.qza\" \\\n",
        "    --o-denoising-stats \"qiime/stats.qza\" \\\n",
        "    --p-n-threads 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved Visualization to: qiime/table.qzv\u001b[0m\n",
            "\u001b[?25h\u001b[0m/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved Visualization to: qiime/rep-seqs.qzv\u001b[0m\n",
            "\u001b[?25h\u001b[0m/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved Visualization to: qiime/stats.qzv\u001b[0m\n",
            "\u001b[?25h\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Now we convert the dada2 artefacts in the previous cell to visualisations\n",
        "# If it passes the QC, we can proceed to assign taxonomy\n",
        "!qiime feature-table summarize \\\n",
        "    --i-table \"qiime/table.qza\" \\\n",
        "    --o-visualization \"qiime/table.qzv\" \\\n",
        "    --m-sample-metadata-file \"metadata.tsv\"\n",
        "\n",
        "!qiime feature-table tabulate-seqs \\\n",
        "    --i-data \"qiime/rep-seqs.qza\" \\\n",
        "    --o-visualization \"qiime/rep-seqs.qzv\"\n",
        "\n",
        "!qiime metadata tabulate \\\n",
        "    --m-input-file \"qiime/stats.qza\" \\\n",
        "    --o-visualization \"qiime/stats.qzv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved FeatureData[Taxonomy] to: qiime/taxonomy.qza\u001b[0m\n",
            "\u001b[?25h\u001b[0m/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved Visualization to: qiime/taxonomy.qzv\u001b[0m\n",
            "\u001b[?25h\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Point this to your actual classifier\n",
        "classifier_path = \"/home/patwuch/projects/microbiome/reference/silva-138-99-nb-classifier.qza\"\n",
        "\n",
        "!qiime feature-classifier classify-sklearn \\\n",
        "    --i-classifier {classifier_path} \\\n",
        "    --i-reads \"qiime/rep-seqs.qza\" \\\n",
        "    --o-classification \"qiime/taxonomy.qza\"\n",
        "\n",
        "# Exhaustive list of taxonomic assignments with confidence scores\n",
        "!qiime metadata tabulate \\\n",
        "    --m-input-file \"qiime/taxonomy.qza\" \\\n",
        "    --o-visualization \"qiime/taxonomy.qzv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved Visualization to: qiime/taxa-bar-plots.qzv\u001b[0m\n",
            "\u001b[?25h\u001b[0m/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved Visualization to: qiime/krona.qzv\u001b[0m\n",
            "\u001b[?25h\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Taxa bar plots are a common way to visualise taxonomic composition across samples\n",
        "!qiime taxa barplot \\\n",
        "    --i-table \"qiime/table.qza\" \\\n",
        "    --i-taxonomy \"qiime/taxonomy.qza\" \\\n",
        "    --m-metadata-file \"metadata.tsv\" \\\n",
        "    --o-visualization \"qiime/taxa-bar-plots.qzv\"\n",
        "\n",
        "# Krona is a helpful way to interactively explore taxonomic composition\n",
        "# But it is not great for static figures in publications\n",
        "!qiime krona collapse-and-plot \\\n",
        "    --i-table \"qiime/table.qza\" \\\n",
        "    --i-taxonomy \"qiime/taxonomy.qza\" \\\n",
        "    --o-krona-plot \"qiime/krona.qzv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "002bf6e3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mExported qiime/table.qza as BIOMV210DirFmt to directory exported/exported-feature-table\u001b[0m\n",
            "\u001b[?25h\u001b[0m/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mExported qiime/taxonomy.qza as TSVTaxonomyDirectoryFormat to directory exported/exported-taxonomy\u001b[0m\n",
            "\u001b[?25h\u001b[0m"
          ]
        }
      ],
      "source": [
        "# If you want static plots of alpha and beta diversity as png, you must use the following commands\n",
        "# These export qiime artefacts into more standard bioinformatics file formats\n",
        "!qiime tools export \\\n",
        "  --input-path qiime/table.qza \\\n",
        "  --output-path exported/exported-feature-table\n",
        "\n",
        "!qiime tools export \\\n",
        "  --input-path qiime/taxonomy.qza \\\n",
        "  --output-path exported/exported-taxonomy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "6b012c1d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Kingdom...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_188986/3147252898.py:41: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
            "  df_tax = df.groupby(taxonomy[tax_level], axis=1).sum()\n",
            "/tmp/ipykernel_188986/3147252898.py:56: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
            "  cmap = cm.get_cmap('tab20', n_colors)  # Using tab20 colormap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Phylum...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_188986/3147252898.py:41: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
            "  df_tax = df.groupby(taxonomy[tax_level], axis=1).sum()\n",
            "/tmp/ipykernel_188986/3147252898.py:56: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
            "  cmap = cm.get_cmap('tab20', n_colors)  # Using tab20 colormap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Class...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_188986/3147252898.py:41: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
            "  df_tax = df.groupby(taxonomy[tax_level], axis=1).sum()\n",
            "/tmp/ipykernel_188986/3147252898.py:56: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
            "  cmap = cm.get_cmap('tab20', n_colors)  # Using tab20 colormap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Order...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_188986/3147252898.py:41: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
            "  df_tax = df.groupby(taxonomy[tax_level], axis=1).sum()\n",
            "/tmp/ipykernel_188986/3147252898.py:56: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
            "  cmap = cm.get_cmap('tab20', n_colors)  # Using tab20 colormap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Family...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_188986/3147252898.py:41: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
            "  df_tax = df.groupby(taxonomy[tax_level], axis=1).sum()\n",
            "/tmp/ipykernel_188986/3147252898.py:56: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
            "  cmap = cm.get_cmap('tab20', n_colors)  # Using tab20 colormap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Genus...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_188986/3147252898.py:41: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
            "  df_tax = df.groupby(taxonomy[tax_level], axis=1).sum()\n",
            "/tmp/ipykernel_188986/3147252898.py:56: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
            "  cmap = cm.get_cmap('tab20', n_colors)  # Using tab20 colormap\n"
          ]
        }
      ],
      "source": [
        "output_dir = \"taxa_barplots\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ===========================\n",
        "# USER SETTINGS\n",
        "# ===========================\n",
        "feature_table_biom = \"exported/exported-feature-table/feature-table.biom\"\n",
        "taxonomy_tsv = \"exported/exported-taxonomy/taxonomy.tsv\"\n",
        "top_n = 20            # Number of taxa to show in legend\n",
        "\n",
        "# ===========================\n",
        "# LOAD DATA\n",
        "# ===========================\n",
        "table = biom.load_table(feature_table_biom)\n",
        "df = pd.DataFrame(table.matrix_data.toarray().T, \n",
        "                  index=table.ids(axis='sample'), \n",
        "                  columns=table.ids(axis='observation'))\n",
        "\n",
        "taxonomy = pd.read_csv(taxonomy_tsv, sep='\\t', index_col=0)\n",
        "\n",
        "# Here we only map taxa to the 6th level because this protocol\n",
        "# can only identify specific genuses\n",
        "level_dict = {\n",
        "    \"Kingdom\": 0,\n",
        "    \"Phylum\": 1,\n",
        "    \"Class\": 2,\n",
        "    \"Order\": 3,\n",
        "    \"Family\": 4,\n",
        "    \"Genus\": 5,\n",
        "}\n",
        "\n",
        "# ===========================\n",
        "# LOOP THROUGH TAXONOMIC LEVELS\n",
        "# ===========================\n",
        "for tax_level, level_index in level_dict.items():\n",
        "    print(f\"Processing {tax_level}...\")\n",
        "\n",
        "    taxonomy[tax_level] = taxonomy['Taxon'].str.split(';').str[level_index]\n",
        "    taxonomy[tax_level] = taxonomy[tax_level].fillna(\"Unassigned\")\n",
        "\n",
        "    df_tax = df.groupby(taxonomy[tax_level], axis=1).sum()\n",
        "    df_tax_norm = df_tax.div(df_tax.sum(axis=1), axis=0)\n",
        "\n",
        "    mean_abundance = df_tax_norm.mean(axis=0)\n",
        "    top_taxa = mean_abundance.sort_values(ascending=False).head(top_n).index\n",
        "    df_top = df_tax_norm[top_taxa].copy()\n",
        "    df_top['Other'] = df_tax_norm.drop(columns=top_taxa).sum(axis=1)\n",
        "\n",
        "    # Reverse columns for correct stacking/legend\n",
        "    df_top_plot = df_top[df_top.columns[::-1]]  \n",
        "\n",
        "    # ===========================\n",
        "    # CREATE A CLEAN COLOR SCHEME\n",
        "    # ===========================\n",
        "    n_colors = df_top_plot.shape[1]\n",
        "    cmap = cm.get_cmap('tab20', n_colors)  # Using tab20 colormap\n",
        "    colors = [cmap(i) for i in range(n_colors)]\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(12,6))\n",
        "    df_top_plot.plot(kind='bar', stacked=True, width=0.8, ax=plt.gca(), color=colors)\n",
        "    plt.ylabel(\"Relative abundance\")\n",
        "    plt.xlabel(\"Samples\")\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.title(f\"Relative abundance at {tax_level} level\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    output_png = f\"taxa_barplots/taxa_barplot_{tax_level}.png\"\n",
        "    plt.savefig(output_png, dpi=300)\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a26397e",
      "metadata": {},
      "source": [
        "In Section 3, we must make an important decision: to create phylogenetic trees or not. You can just use all non-phylogenetic metrics if this is irrelevant for your study, but creating a tree will allow you compute metrics of your data that provide certain biological angles (e.g. evolutionary closeness, functional prediction...). \n",
        "\n",
        "(0) Non-phylogenetic metrics: No tree. Limits some metrics you can compute which will be mentioned later sections.\n",
        "\n",
        "It does take more time if you want a phylogenetic tree, so here I provide three approaches to tree creation ranked from fast to slow. The more an approach relies on external data, the faster it tends to be.\n",
        "\n",
        "(1) Closed-reference clustering: Rely on existing database, super fast but drops novel sequences, good for huge datasets\n",
        "\n",
        "(2) Fragment insertion via SEPP: Also relies on existing database, good speed and keeps novel sequences by finding close matches\n",
        "\n",
        "(3) De novo tree: Build tree from scratch, might take hours and lots of RAM, keeps exact novel sequences but might not align well with other research paper's findings (ONLY USE WHEN YOU ARE TRYING TO IDENTIFY RELATIVELY NEW SPECIES)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e2b04c6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved FeatureTable[Frequency] to: core-metrics-results/rarefied_table.qza\u001b[0m\n",
            "\u001b[32mSaved SampleData[AlphaDiversity] to: core-metrics-results/observed_features_vector.qza\u001b[0m\n",
            "\u001b[32mSaved SampleData[AlphaDiversity] to: core-metrics-results/shannon_vector.qza\u001b[0m\n",
            "\u001b[32mSaved SampleData[AlphaDiversity] to: core-metrics-results/evenness_vector.qza\u001b[0m\n",
            "\u001b[32mSaved DistanceMatrix to: core-metrics-results/jaccard_distance_matrix.qza\u001b[0m\n",
            "\u001b[32mSaved DistanceMatrix to: core-metrics-results/bray_curtis_distance_matrix.qza\u001b[0m\n",
            "\u001b[32mSaved PCoAResults to: core-metrics-results/jaccard_pcoa_results.qza\u001b[0m\n",
            "\u001b[32mSaved PCoAResults to: core-metrics-results/bray_curtis_pcoa_results.qza\u001b[0m\n",
            "\u001b[32mSaved Visualization to: core-metrics-results/jaccard_emperor.qzv\u001b[0m\n",
            "\u001b[32mSaved Visualization to: core-metrics-results/bray_curtis_emperor.qzv\u001b[0m\n",
            "\u001b[?25h\u001b[0m"
          ]
        }
      ],
      "source": [
        "'''APPROACH 0: No Phylogeny\n",
        "This cells skips the phylogenetic tree construction step and \n",
        "directly computes non-phylogenetic core metrics.'''\n",
        "# Remove core-metrics-results first if it exists\n",
        "!rm -rf core-metrics-results\n",
        "# Run non-phylogenetic core metrics\n",
        "!qiime diversity core-metrics \\\n",
        "  --i-table \"qiime/table.qza\" \\\n",
        "  --p-sampling-depth 36759 \\\n",
        "  --m-metadata-file \"metadata.tsv\" \\\n",
        "  --output-dir \"core-metrics-results\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "bdc7f4e6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Usage: \u001b[94mqiime rescript parse-silva-taxonomy\u001b[0m [OPTIONS]\n",
            "\n",
            "  Parses several files from the SILVA reference database to produce a\n",
            "  GreenGenes-like fixed rank taxonomy that is 6 or 7 ranks deep, depending on\n",
            "  whether or not `include_species_labels` is applied. The generated ranks (and\n",
            "  the rank handles used to label these ranks in the resulting taxonomy) are:\n",
            "  domain (d__), phylum (p__), class (c__), order (o__), family (f__), genus\n",
            "  (g__), and species (s__). NOTE: THIS ACTION ACQUIRES DATA FROM THE SILVA\n",
            "  DATABASE. SEE https://www.arb-silva.de/silva-license-information/ FOR MORE\n",
            "  INFORMATION and be aware that earlier versions may be released under a\n",
            "  different license.\n",
            "\n",
            "\u001b[1mInputs\u001b[0m:\n",
            "  \u001b[94m\u001b[4m--i-taxonomy-tree\u001b[0m ARTIFACT\n",
            "    \u001b[32mPhylogeny[Rooted]\u001b[0m    SILVA hierarchical taxonomy tree. The SILVA release\n",
            "                         filename typically takes the form of:\n",
            "                         'tax_slv_ssu_X.tre', where 'X' is the SILVA version\n",
            "                         number.                                    \u001b[35m[required]\u001b[0m\n",
            "  \u001b[94m\u001b[4m--i-taxonomy-map\u001b[0m ARTIFACT \u001b[32mFeatureData[SILVATaxidMap]\u001b[0m\n",
            "                         SILVA taxonomy map. This file contains a mapping of\n",
            "                         the sequence accessions to the numeric taxonomy\n",
            "                         identifiers and species label information. The SILVA\n",
            "                         release filename is typically in the form of:\n",
            "                         'taxmap_slv_ssu_ref_X.txt', or\n",
            "                         'taxmap_slv_ssu_ref_nr_X.txt' where 'X' is the SILVA\n",
            "                         version number.                            \u001b[35m[required]\u001b[0m\n",
            "  \u001b[94m\u001b[4m--i-taxonomy-ranks\u001b[0m ARTIFACT \u001b[32mFeatureData[SILVATaxonomy]\u001b[0m\n",
            "                         SILVA taxonomy file. This file contains the\n",
            "                         taxonomic rank information for each numeric taxonomy\n",
            "                         identifier and the taxonomy. The SILVA  filename\n",
            "                         typically takes the form of: 'tax_slv_ssu_X.txt',\n",
            "                         where 'X' is the SILVA version number.     \u001b[35m[required]\u001b[0m\n",
            "\u001b[1mParameters\u001b[0m:\n",
            "  \u001b[94m--p-rank-propagation\u001b[0m / \u001b[94m--p-no-rank-propagation\u001b[0m\n",
            "                         If a rank has no taxonomy associated with it, the\n",
            "                         taxonomy from the upper-level rank of that lineage,\n",
            "                         will be propagated downward. For example, if we are\n",
            "                         missing the genus label for 'f__Pasteurellaceae;\n",
            "                         g__'then the 'f__' rank will be propagated to become:\n",
            "                         'f__Pasteurellaceae; g__Pasteurellaceae'.\n",
            "                                                               \u001b[35m[default: True]\u001b[0m\n",
            "  \u001b[94m--p-ranks\u001b[0m TEXT... \u001b[32mChoices('domain', 'superkingdom', 'kingdom',\u001b[0m\n",
            "    \u001b[32m'subkingdom', 'superphylum', 'phylum', 'subphylum', 'infraphylum',\u001b[0m\n",
            "    \u001b[32m'superclass', 'class', 'subclass', 'infraclass', 'superorder', 'order',\u001b[0m\n",
            "    \u001b[32m'suborder', 'superfamily', 'family', 'subfamily', 'genus')\u001b[0m\n",
            "                         List of taxonomic ranks for building a taxonomy from\n",
            "                         the SILVA Taxonomy database. Use\n",
            "                         '\u001b[4minclude-species-labels\u001b[0m' to append the organism name\n",
            "                         as the species label. [default: 'domain', 'phylum',\n",
            "                         'class', 'order', 'family', 'genus']       \u001b[35m[optional]\u001b[0m\n",
            "  \u001b[94m--p-include-species-labels\u001b[0m / \u001b[94m--p-no-include-species-labels\u001b[0m\n",
            "                         Include species rank labels in taxonomy output.\n",
            "                         Note: species-labels may not be reliable in all\n",
            "                         cases.                               \u001b[35m[default: False]\u001b[0m\n",
            "\u001b[1mOutputs\u001b[0m:\n",
            "  \u001b[94m\u001b[4m--o-taxonomy\u001b[0m ARTIFACT \u001b[32mFeatureData[Taxonomy]\u001b[0m\n",
            "                         The resulting fixed-rank formatted SILVA taxonomy.\n",
            "                                                                    \u001b[35m[required]\u001b[0m\n",
            "\u001b[1mMiscellaneous\u001b[0m:\n",
            "  \u001b[94m--output-dir\u001b[0m PATH      Output unspecified results to a directory\n",
            "  \u001b[94m--verbose\u001b[0m / \u001b[94m--quiet\u001b[0m    Display verbose output to stdout and/or stderr\n",
            "                         during execution of this action. Or silence output if\n",
            "                         execution is successful (silence is golden).\n",
            "  \u001b[94m--example-data\u001b[0m PATH    Write example data and exit.\n",
            "  \u001b[94m--citations\u001b[0m            Show citations and exit.\n",
            "  \u001b[94m--use-cache\u001b[0m DIRECTORY  Specify the cache to be used for the intermediate\n",
            "                         work of this action. If not provided, the default\n",
            "                         cache under $TMP/qiime2/<uname> will be used.\n",
            "                         IMPORTANT FOR HPC USERS: If you are on an HPC system\n",
            "                         and are using parallel execution it is important to\n",
            "                         set this to a location that is globally accessible to\n",
            "                         all nodes in the cluster.\n",
            "  \u001b[94m--help\u001b[0m                 Show this message and exit.\n",
            "\n",
            "\u001b[33m                  There were some problems with the command:                  \u001b[0m\n",
            "\u001b[31m\u001b[1m (1/3?) No such option: --i-silva-fasta\u001b[0m\n",
            "\u001b[31m\u001b[1m (2/3?) No such option: --o-sequence-file\u001b[0m\n",
            "\u001b[31m\u001b[1m (3/3?) No such option: --o-taxonomy-file Did you mean --o-taxonomy?\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!qiime rescript parse-silva-taxonomy \\\n",
        "  --i-silva-fasta /home/patwuch/projects/microbiome/reference/SILVA_138.2_SSURef_NR99_tax_silva.fasta \\\n",
        "  --o-sequence-file /home/patwuch/projects/microbiome/reference/silva-ref-seqs.fasta \\\n",
        "  --o-taxonomy-file /home/patwuch/projects/microbiome/reference/silva-ref-taxonomy.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3eb44cf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31m\u001b[1mError: QIIME 2 has no plugin/command named 'greengenes2'.\u001b[0m\n",
            "/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "Exception ignored in: <function Forward.__del__ at 0x74175194bac0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/pyparsing/core.py\", line 5624, in __del__\n",
            "    def __del__(self):\n",
            "KeyboardInterrupt: \n",
            "^C\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ],
      "source": [
        "'''APPROACH 1: Closed Reference Clustering'''\n",
        "# Remove previous results if they exist\n",
        "!rm -rf core-metrics-results\n",
        "\n",
        "# Paths to SILVA references\n",
        "silva_seqs=\"/home/patwuch/projects/microbiome/reference/silva-138-99-seqs.qza\"\n",
        "silva_tree=\"/path/to/silva-138-99-tree.qza\"\n",
        "\n",
        "# Map sequences to SILVA reference (closed-reference style)\n",
        "!qiime feature-classifier classify-consensus-blast \\\n",
        "  --i-query qiime/rep-seqs.qza \\\n",
        "  --i-reference-reads \"$silva_seqs\" \\\n",
        "  --i-reference-taxonomy \"/path/to/silva-138-99-tax.qza\" \\\n",
        "  --p-perc-identity 0.97 \\\n",
        "  --o-classification qiime/silva-classification.qza\n",
        "\n",
        "!qiime vsearch cluster-features-closed-reference \\\n",
        "  --i-table qiime/table.qza \\\n",
        "  --i-sequences qiime/rep-seqs.qza \\\n",
        "  --i-reference-sequences \"$silva_seqs\" \\\n",
        "  --p-perc-identity 0.97 \\\n",
        "  --o-clustered-table qiime/silva-mapped-table.qza \\\n",
        "  --o-clustered-sequences qiime/silva-mapped-seqs.qza\n",
        "\n",
        "!qiime diversity core-metrics-phylogenetic \\\n",
        "  --i-table qiime/silva-mapped-table.qza \\\n",
        "  --i-phylogeny \"$silva_tree\" \\\n",
        "  --p-sampling-depth 36759 \\\n",
        "  --m-metadata-file metadata.tsv \\\n",
        "  --output-dir core-metrics-results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc3a1b60",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Import pre-built Greengenes2 tree\n",
        "!qiime tools import \\\n",
        "  --type 'Phylogeny[Rooted]' \\\n",
        "  --input-path gg2-backbone-tree-rooted.nwk \\\n",
        "  --output-path gg2-rooted-tree.qza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f0c2562",
      "metadata": {},
      "outputs": [],
      "source": [
        "!qiime fragment-insertion sepp \\\n",
        "  --i-representative-sequences rep-seqs.qza \\\n",
        "  --i-reference-alignment silva_138_99_alignment.qza \\\n",
        "  --i-reference-phylogeny silva_138_99_tree.qza \\\n",
        "  --o-tree insertion-tree.qza \\\n",
        "  --o-placements insertion-placements.qza\n",
        "\n",
        "# Compute phylogenetic metrics using the inserted tree\n",
        "!qiime diversity core-metrics-phylogenetic \\\n",
        "  --i-table table.qza \\\n",
        "  --i-phylogeny insertion-tree.qza \\\n",
        "  --p-sampling-depth 10000 \\\n",
        "  --m-metadata-file metadata.tsv \\\n",
        "  --output-dir core-metrics-results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved FeatureTable[Frequency] to: core-metrics-results/rarefied_table.qza\u001b[0m\n",
            "\u001b[32mSaved SampleData[AlphaDiversity] to: core-metrics-results/faith_pd_vector.qza\u001b[0m\n",
            "\u001b[32mSaved SampleData[AlphaDiversity] to: core-metrics-results/observed_features_vector.qza\u001b[0m\n",
            "\u001b[32mSaved SampleData[AlphaDiversity] to: core-metrics-results/shannon_vector.qza\u001b[0m\n",
            "\u001b[32mSaved SampleData[AlphaDiversity] to: core-metrics-results/evenness_vector.qza\u001b[0m\n",
            "\u001b[32mSaved DistanceMatrix to: core-metrics-results/unweighted_unifrac_distance_matrix.qza\u001b[0m\n",
            "\u001b[32mSaved DistanceMatrix to: core-metrics-results/weighted_unifrac_distance_matrix.qza\u001b[0m\n",
            "\u001b[32mSaved DistanceMatrix to: core-metrics-results/jaccard_distance_matrix.qza\u001b[0m\n",
            "\u001b[32mSaved DistanceMatrix to: core-metrics-results/bray_curtis_distance_matrix.qza\u001b[0m\n",
            "\u001b[32mSaved PCoAResults to: core-metrics-results/unweighted_unifrac_pcoa_results.qza\u001b[0m\n",
            "\u001b[32mSaved PCoAResults to: core-metrics-results/weighted_unifrac_pcoa_results.qza\u001b[0m\n",
            "\u001b[32mSaved PCoAResults to: core-metrics-results/jaccard_pcoa_results.qza\u001b[0m\n",
            "\u001b[32mSaved PCoAResults to: core-metrics-results/bray_curtis_pcoa_results.qza\u001b[0m\n",
            "\u001b[32mSaved Visualization to: core-metrics-results/unweighted_unifrac_emperor.qzv\u001b[0m\n",
            "\u001b[32mSaved Visualization to: core-metrics-results/weighted_unifrac_emperor.qzv\u001b[0m\n",
            "\u001b[32mSaved Visualization to: core-metrics-results/jaccard_emperor.qzv\u001b[0m\n",
            "\u001b[32mSaved Visualization to: core-metrics-results/bray_curtis_emperor.qzv\u001b[0m\n",
            "\u001b[?25h\u001b[0m"
          ]
        }
      ],
      "source": [
        "'''APPROACH 4: De Novo Phylogeny\n",
        "This cell creates a de novo phylogenetic tree from the representative sequences'''\n",
        "# We call the tree construction function from QIIME2\n",
        "# It will create both a rooted and unrooted tree\n",
        "!qiime phylogeny align-to-tree-mafft-fasttree \\\n",
        "    --i-sequences \"qiime/rep-seqs.qza\" \\\n",
        "    --o-alignment \"qiime/aligned-rep-seqs.qza\" \\\n",
        "    --o-masked-alignment \"qiime/masked-aligned-rep-seqs.qza\" \\\n",
        "    --o-tree \"qiime/unrooted-tree.qza\" \\\n",
        "    --o-rooted-tree \"qiime/rooted-tree.qza\"\n",
        "    \n",
        "# Now based on the phylogenetic tree, we can calculate phylogenetic core metrics\n",
        "# Once again, pick a sampling depth based on the feature table summary\n",
        "!qiime diversity core-metrics-phylogenetic \\\n",
        "    --i-phylogeny \"qiime/rooted-tree.qza\" \\\n",
        "    --i-table \"qiime/table.qza\" \\\n",
        "    --p-sampling-depth 36759 \\\n",
        "    --m-metadata-file \"metadata.tsv\" \\\n",
        "    --output-dir \"core-metrics-results\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2296c3da",
      "metadata": {},
      "outputs": [],
      "source": [
        "!qiime diversity core-metrics \\\n",
        "    --i-table \"qiime/table.qza\" \\\n",
        "    --p-sampling-depth 36759 \\\n",
        "    --m-metadata-file \"metadata.tsv\" \\\n",
        "    --output-dir \"core-metrics-results\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1462e9d5",
      "metadata": {},
      "source": [
        "Section 4 we create alpha and beta diversity visualisations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b912bb61",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/q2_types/sample_data/_deferred_setup/_transformers.py:28: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[cols] = df[cols].apply(pd.to_numeric, errors='ignore')\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/q2_types/sample_data/_deferred_setup/_transformers.py:28: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[cols] = df[cols].apply(pd.to_numeric, errors='ignore')\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/q2_types/sample_data/_deferred_setup/_transformers.py:28: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[cols] = df[cols].apply(pd.to_numeric, errors='ignore')\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/q2_types/sample_data/_deferred_setup/_transformers.py:28: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[cols] = df[cols].apply(pd.to_numeric, errors='ignore')\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
            "  data_subset = grouped_data.get_group(pd_key)\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
            "  data_subset = grouped_data.get_group(pd_key)\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
            "  data_subset = grouped_data.get_group(pd_key)\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
            "  data_subset = grouped_data.get_group(pd_key)\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
            "  data_subset = grouped_data.get_group(pd_key)\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
            "  data_subset = grouped_data.get_group(pd_key)\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
            "  data_subset = grouped_data.get_group(pd_key)\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
            "  data_subset = grouped_data.get_group(pd_key)\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
            "  data_subset = grouped_data.get_group(pd_key)\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
            "  data_subset = grouped_data.get_group(pd_key)\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
            "  data_subset = grouped_data.get_group(pd_key)\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
            "  data_subset = grouped_data.get_group(pd_key)\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
            "  data_subset = grouped_data.get_group(pd_key)\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
            "  data_subset = grouped_data.get_group(pd_key)\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
            "  data_subset = grouped_data.get_group(pd_key)\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context('mode.use_inf_as_na', True):\n",
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/seaborn/_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
            "  data_subset = grouped_data.get_group(pd_key)\n"
          ]
        }
      ],
      "source": [
        "# ---- Load alpha diversity artifacts ----\n",
        "shannon = qiime2.Artifact.load(\"core-metrics-results/shannon_vector.qza\").view(pd.Series)\n",
        "evenness = qiime2.Artifact.load(\"core-metrics-results/evenness_vector.qza\").view(pd.Series)\n",
        "faith = qiime2.Artifact.load(\"core-metrics-results/faith_pd_vector.qza\").view(pd.Series)\n",
        "observed = qiime2.Artifact.load(\"core-metrics-results/observed_features_vector.qza\").view(pd.Series)\n",
        "\n",
        "# ---- Load metadata ----\n",
        "metadata = pd.read_csv(\"metadata.tsv\", sep=\"\\t\", index_col=0)\n",
        "\n",
        "# ---- Combine alpha diversity into one DataFrame ----\n",
        "alpha_df = pd.concat([\n",
        "    shannon.rename(\"Shannon\"),\n",
        "    evenness.rename(\"Evenness\"),\n",
        "    faith.rename(\"Faith_PD\"),\n",
        "    observed.rename(\"Observed_Features\")\n",
        "], axis=1)\n",
        "\n",
        "# ---- Merge alpha diversity with metadata ----\n",
        "merged = alpha_df.join(metadata)\n",
        "\n",
        "# ---- Output folder ----\n",
        "os.makedirs(\"alpha_diversity_plots\", exist_ok=True)\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# ---- Define comparisons in flexible style ----\n",
        "comparisons = [\n",
        "    (\"Group\", None),                # all groups\n",
        "    (\"Group\", [\"OVA\", \"Control\"]),  # only C subgroups\n",
        "    (\"Group\", [\"ACC\", \"OVA\"]),      # only E subgroups\n",
        "    (\"Group\", [\"Control\", \"ACC\"]),  # main type comparison\n",
        "]\n",
        "\n",
        "# ---- Function to plot alpha diversity ----\n",
        "def plot_alpha_diversity(df, x_col, levels=None, title=None, outfile=None):\n",
        "    # Subset if levels provided\n",
        "    if levels is not None:\n",
        "        df = df[df[x_col].isin(levels)]\n",
        "    \n",
        "    # Melt for seaborn\n",
        "    melted = df.melt(\n",
        "        id_vars=[x_col],\n",
        "        value_vars=[\"Shannon\", \"Evenness\", \"Faith_PD\", \"Observed_Features\"],\n",
        "        var_name=\"Metric\",\n",
        "        value_name=\"Diversity\"\n",
        "    )\n",
        "    \n",
        "    # Plot\n",
        "    g = sns.catplot(\n",
        "        data=melted,\n",
        "        x=x_col, y=\"Diversity\",\n",
        "        col=\"Metric\",\n",
        "        kind=\"box\",\n",
        "        col_wrap=2,\n",
        "        sharey=False,\n",
        "        height=4, aspect=1.2\n",
        "    )\n",
        "    g.map_dataframe(sns.stripplot, x=x_col, y=\"Diversity\", color=\"black\", alpha=0.5)\n",
        "    plt.subplots_adjust(top=0.85)\n",
        "    \n",
        "    if title:\n",
        "        g.figure.suptitle(title)\n",
        "    if outfile:\n",
        "        g.savefig(outfile, dpi=300, bbox_inches=\"tight\")\n",
        "    plt.close(g.fig)\n",
        "\n",
        "# ---- Loop over comparisons ----\n",
        "for x_col, levels in comparisons:\n",
        "    name = f\"{x_col}_{'_'.join(levels) if levels else 'all'}\"\n",
        "    title = f\"Alpha Diversity - {name.replace('_', ' ')}\"\n",
        "    outfile = f\"alpha_diversity_plots/alpha_diversity_{name}.png\"\n",
        "    \n",
        "    plot_alpha_diversity(\n",
        "        df=merged,\n",
        "        x_col=x_col,\n",
        "        levels=levels,\n",
        "        title=title,\n",
        "        outfile=outfile\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Load PCoAResults directly from subfolder to plot beta diversity\n",
        "pcoa_results = {\n",
        "    \"Bray-Curtis\": qiime2.Artifact.load(\"core-metrics-results/bray_curtis_pcoa_results.qza\").view(OrdinationResults),\n",
        "    \"Jaccard\": qiime2.Artifact.load(\"core-metrics-results/jaccard_pcoa_results.qza\").view(OrdinationResults),\n",
        "    \"Unweighted UniFrac\": qiime2.Artifact.load(\"core-metrics-results/unweighted_unifrac_pcoa_results.qza\").view(OrdinationResults),\n",
        "    \"Weighted UniFrac\": qiime2.Artifact.load(\"core-metrics-results/weighted_unifrac_pcoa_results.qza\").view(OrdinationResults),\n",
        "}\n",
        "\n",
        "metadata = pd.read_csv(\"metadata.tsv\", sep=\"\\t\", index_col=0)\n",
        "\n",
        "# Number of PCs to rename\n",
        "n_pcs = 8\n",
        "\n",
        "# ---- Define comparisons in flexible style ----\n",
        "comparisons = [\n",
        "    (\"Group\", None),                # all groups\n",
        "    # (\"Group\", [\"OVA\", \"Control\"]),  # only C subgroups\n",
        "    # (\"Group\", [\"E\", \"EH\", \"EL\"]),  # only E subgroups\n",
        "    # (\"MainType\", [\"C\", \"E\"])       # main type comparison\n",
        "]\n",
        "\n",
        "# Output folder\n",
        "output_dir = \"beta_diversity_plots\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Loop through comparisons\n",
        "for col, filter_values in comparisons:\n",
        "    # Create figure with 2x2 grid\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for ax, (distance_metric, pcoa_res) in zip(axes, pcoa_results.items()):\n",
        "        coords = pcoa_res.samples\n",
        "        df = coords.merge(metadata, left_index=True, right_index=True)\n",
        "        df.rename(columns={i: f'PC{i+1}' for i in range(n_pcs)}, inplace=True)\n",
        "\n",
        "        df_subset = df.copy()\n",
        "        if filter_values is not None:\n",
        "            df_subset = df_subset[df_subset[col].isin(filter_values)]\n",
        "\n",
        "        unique_groups = df_subset[col].unique()\n",
        "        palette = sns.color_palette(n_colors=len(unique_groups))\n",
        "        group_to_color = dict(zip(unique_groups, palette))\n",
        "\n",
        "        # Scatter plot\n",
        "        sns.scatterplot(\n",
        "            x=\"PC1\", y=\"PC2\", hue=col, data=df_subset,\n",
        "            s=100, alpha=0.8, palette=group_to_color, ax=ax\n",
        "        )\n",
        "\n",
        "        # Draw ellipses\n",
        "        for group, data_subset in df_subset.groupby(col):\n",
        "            if len(data_subset) < 2:\n",
        "                continue\n",
        "            centroid_x = data_subset[\"PC1\"].mean()\n",
        "            centroid_y = data_subset[\"PC2\"].mean()\n",
        "\n",
        "            width = data_subset[\"PC1\"].std() * 2\n",
        "            height = data_subset[\"PC2\"].std() * 2\n",
        "\n",
        "            ellipse = Ellipse(\n",
        "                (centroid_x, centroid_y),\n",
        "                width=width, height=height,\n",
        "                edgecolor=group_to_color[group],\n",
        "                facecolor='none', lw=2, alpha=0.7\n",
        "            )\n",
        "            ax.add_patch(ellipse)\n",
        "            ax.scatter(centroid_x, centroid_y, marker='x', color='black', s=120, zorder=10)\n",
        "\n",
        "        ax.set_title(distance_metric)\n",
        "        ax.set_xlabel(\"PC1\")\n",
        "        ax.set_ylabel(\"PC2\")\n",
        "\n",
        "    # Adjust legend → only show one combined legend outside the grid\n",
        "    handles, labels = axes[0].get_legend_handles_labels()\n",
        "    fig.legend(handles, labels, title=col, bbox_to_anchor=(1.05, 0.5), loc='center left')\n",
        "\n",
        "    # Main title\n",
        "    subset_label = \"all\" if filter_values is None else \"_\".join(filter_values)\n",
        "    fig.suptitle(f\"PCoA comparison ({col} = {subset_label})\", fontsize=16)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 0.85, 0.95])\n",
        "\n",
        "    # Save figure\n",
        "    filename = f\"PCoA_comparison_{col}_{subset_label}.png\"\n",
        "    filepath = os.path.join(output_dir, filename)\n",
        "    plt.savefig(filepath, dpi=300)\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mExported qiime/rooted-tree.qza as NewickDirectoryFormat to directory exported/rooted-tree\u001b[0m\n",
            "\u001b[?25h\u001b[0m/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mExported qiime/taxonomy.qza as TSVTaxonomyDirectoryFormat to directory exported/taxonomy\u001b[0m\n",
            "\u001b[?25h\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Export rooted tree and taxonomy for use in R or other software\n",
        "!qiime tools export \\\n",
        "    --input-path \"qiime/rooted-tree.qza\" \\\n",
        "    --output-path \"exported/rooted-tree\"\n",
        "!qiime tools export \\\n",
        "    --input-path \"qiime/taxonomy.qza\" \\\n",
        "    --output-path \"exported/taxonomy\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88f87cd5",
      "metadata": {},
      "source": [
        "Section 5 we create the PERMANOVA and BETADISPER tables using a combination of python and R, as R creates more legible results than qiime in this case.\n",
        "\n",
        "!!! The R cell will not run if you do not run the below cell to initiate R magic first !!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "11e784bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext rpy2.ipython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "1ef3b825",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mExported core-metrics-results/weighted_unifrac_distance_matrix.qza as DistanceMatrixDirectoryFormat to directory _tmp_export_weighted_unifrac\u001b[0m\n",
            "\u001b[?25h\u001b[0m/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mExported core-metrics-results/unweighted_unifrac_distance_matrix.qza as DistanceMatrixDirectoryFormat to directory _tmp_export_unweighted_unifrac\u001b[0m\n",
            "\u001b[?25h\u001b[0m/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mExported core-metrics-results/jaccard_distance_matrix.qza as DistanceMatrixDirectoryFormat to directory _tmp_export_jaccard\u001b[0m\n",
            "\u001b[?25h\u001b[0m/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mExported core-metrics-results/bray_curtis_distance_matrix.qza as DistanceMatrixDirectoryFormat to directory _tmp_export_bray_curtis\u001b[0m\n",
            "\u001b[?25h\u001b[0m"
          ]
        }
      ],
      "source": [
        "core_metrics_dir = \"core-metrics-results\"\n",
        "qza_files = [f for f in os.listdir(core_metrics_dir) if f.endswith(\"_distance_matrix.qza\")]\n",
        "\n",
        "distance_names = []\n",
        "distance_paths = []\n",
        "\n",
        "for qza in qza_files:\n",
        "    name = qza.replace(\"_distance_matrix.qza\", \"\")\n",
        "    out_path = os.path.join(\"exported\", f\"{name}_distance_matrix.tsv\")\n",
        "\n",
        "    # Make sure export dir exists\n",
        "    os.makedirs(\"exported\", exist_ok=True)\n",
        "\n",
        "    # Use a temp dir for the raw export\n",
        "    tmp_dir = f\"_tmp_export_{name}\"\n",
        "    os.makedirs(tmp_dir, exist_ok=True)\n",
        "\n",
        "    # Export with QIIME2\n",
        "    !qiime tools export --input-path \"{os.path.join(core_metrics_dir, qza)}\" --output-path \"{tmp_dir}\"\n",
        "\n",
        "    # Move the exported file\n",
        "    raw_exported = os.path.join(tmp_dir, \"distance-matrix.tsv\")\n",
        "    if os.path.exists(raw_exported):\n",
        "        shutil.move(raw_exported, out_path)\n",
        "\n",
        "    # Clean up temp dir\n",
        "    shutil.rmtree(tmp_dir)\n",
        "\n",
        "    distance_names.append(name)\n",
        "    distance_paths.append(out_path)\n",
        "\n",
        "# Define comparisons\n",
        "comparison_names = [\"all\"]\n",
        "comparison_columns = [\"Group\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f3d2a1c",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%R -i distance_names -i distance_paths -i comparison_names -i comparison_columns \n",
        "\n",
        "library(vegan)\n",
        "library(dplyr)\n",
        "library(tibble)\n",
        "\n",
        "# Build named lists in R\n",
        "distance_files <- setNames(as.list(distance_paths), distance_names)\n",
        "comparisons <- setNames(as.list(comparison_columns), comparison_names)\n",
        "\n",
        "load_distance <- function(file) {\n",
        "  mat <- as.matrix(read.table(file, header=TRUE, row.names=1, sep=\"\\t\", check.names=FALSE))\n",
        "  as.dist(mat)\n",
        "}\n",
        "\n",
        "# Load metadata\n",
        "meta <- read.table(\"metadata.tsv\", header=TRUE, sep=\"\\t\", row.names=1)\n",
        "\n",
        "# Define allowed levels per comparison to prevent nonsensical outputs\n",
        "allowed_levels <- list(\n",
        "  C_group = c(\"C\", \"CH\", \"CL\"),\n",
        "  E_group = c(\"E\", \"EH\", \"EL\") # Add other comparisons here as needed\n",
        ")\n",
        "\n",
        "results <- list()\n",
        "\n",
        "for (dname in names(distance_files)) {\n",
        "  d <- load_distance(distance_files[[dname]])\n",
        "  \n",
        "  for (comp_name in names(comparisons)) {\n",
        "    col <- comparisons[[comp_name]]\n",
        "    \n",
        "    # Only include the allowed levels for this comparison\n",
        "    factor_levels <- intersect(unique(meta[[col]]), allowed_levels[[comp_name]])\n",
        "    \n",
        "    ## ---- Global PERMANOVA ----\n",
        "    ad_global <- adonis2(d ~ meta[[col]], permutations=9999)\n",
        "    ad_row <- as.data.frame(ad_global[1, ])\n",
        "    ad_row <- rownames_to_column(ad_row, \"Term\")\n",
        "    ad_row$distance <- dname\n",
        "    ad_row$comparison <- comp_name\n",
        "    ad_row$scope <- \"global\"\n",
        "    ad_row$pair <- NA\n",
        "    ad_row$test <- \"permanova\"\n",
        "    results[[length(results)+1]] <- ad_row\n",
        "\n",
        "    ## ---- Global betadisper ----\n",
        "    bd_global <- betadisper(d, meta[[col]])\n",
        "    bd_global_anova <- anova(bd_global)\n",
        "    bd_row <- as.data.frame(bd_global_anova[1, ])\n",
        "    bd_row <- rownames_to_column(bd_row, \"Term\")\n",
        "    bd_row$distance <- dname\n",
        "    bd_row$comparison <- comp_name\n",
        "    bd_row$scope <- \"global\"\n",
        "    bd_row$pair <- NA\n",
        "    bd_row$test <- \"betadisper\"\n",
        "    results[[length(results)+1]] <- bd_row\n",
        "\n",
        "    ## ---- Pairwise ----\n",
        "    if (length(factor_levels) > 1) {  # pairwise only makes sense if >=2 levels\n",
        "      pairs <- combn(factor_levels, 2, simplify = FALSE)\n",
        "      for (p in pairs) {\n",
        "        idx <- meta[[col]] %in% p\n",
        "        d_sub <- as.dist(as.matrix(d)[idx, idx])\n",
        "        meta_sub <- meta[idx, ]\n",
        "        \n",
        "        # PERMANOVA pair\n",
        "        ad_pair <- adonis2(d_sub ~ meta_sub[[col]], permutations=9999)\n",
        "        adp_row <- as.data.frame(ad_pair[1, ])\n",
        "        adp_row <- rownames_to_column(adp_row, \"Term\")\n",
        "        adp_row$distance <- dname\n",
        "        adp_row$comparison <- comp_name\n",
        "        adp_row$scope <- \"pairwise\"\n",
        "        adp_row$pair <- paste(p, collapse=\"_vs_\")\n",
        "        adp_row$test <- \"permanova\"\n",
        "        results[[length(results)+1]] <- adp_row\n",
        "        \n",
        "        # betadisper pair\n",
        "        bd_pair <- betadisper(d_sub, meta_sub[[col]])\n",
        "        bd_pair_anova <- anova(bd_pair)\n",
        "        bdp_row <- as.data.frame(bd_pair_anova[1, ])\n",
        "        bdp_row <- rownames_to_column(bdp_row, \"Term\")\n",
        "        bdp_row$distance <- dname\n",
        "        bdp_row$comparison <- comp_name\n",
        "        bdp_row$scope <- \"pairwise\"\n",
        "        bdp_row$pair <- paste(p, collapse=\"_vs_\")\n",
        "        bdp_row$test <- \"betadisper\"\n",
        "        results[[length(results)+1]] <- bdp_row\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "# Bind all results with clean column ordering\n",
        "permanova_permdisp_results <- bind_rows(results) %>%\n",
        "  select(distance, comparison, scope, pair, test, everything())\n",
        "\n",
        "write.table(\n",
        "  permanova_permdisp_results, \n",
        "  file = \"permanova_permdisp_results.tsv\", \n",
        "  sep = \"\\t\", \n",
        "  quote = FALSE, \n",
        "  row.names = FALSE\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c75afb4",
      "metadata": {},
      "source": [
        "Section 6 to evaluate differential taxa, we use either ANCOMBC or ANCOMBC2.\n",
        "If you want to get full results and static plots, follow the ANCOMBC2 route.\n",
        "If you want to get easy visualisation for Qiime2 View, use the ANCOMBC approach.\n",
        "Either way they should yield similar results so long as your parameters remain consistent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e64188aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ANCOMBC approach\n",
        "# -------------------------------\n",
        "# 1. Compare all 6 groups (Group)\n",
        "# -------------------------------\n",
        "!qiime composition ancombc \\\n",
        "  --i-table \"qiime/table.qza\" \\\n",
        "  --m-metadata-file \"metadata.tsv\" \\\n",
        "  --p-formula Group \\\n",
        "  --o-differentials \"qiime/ancombc-Group-results.qza\"\n",
        "\n",
        "!qiime composition da-barplot \\\n",
        "  --i-data \"qiime/ancombc-Group-results.qza\" \\\n",
        "  --p-significance-threshold 0.001 \\\n",
        "  --o-visualization \"qiime/ancombc-Group-results.qzv\"\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Compare all 6 groups focusing on MainType (E vs C)\n",
        "# -------------------------------\n",
        "!qiime composition ancombc \\\n",
        "  --i-table \"qiime/table.qza\" \\\n",
        "  --m-metadata-file \"metadata.tsv\" \\\n",
        "  --p-formula MainType \\\n",
        "  --o-differentials \"qiime/ancombc-E-vs-C-results.qza\"\n",
        "\n",
        "!qiime composition da-barplot \\\n",
        "  --i-data \"qiime/ancombc-E-vs-C-results.qza\" \\\n",
        "  --p-significance-threshold 0.001 \\\n",
        "  --o-visualization \"qiime/ancombc-E-vs-C-results.qzv\"\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Compare Modifier within MainType E\n",
        "# -------------------------------\n",
        "!qiime feature-table filter-samples \\\n",
        "  --i-table \"qiime/table.qza\" \\\n",
        "  --m-metadata-file \"metadata.tsv\" \\\n",
        "  --p-where \"MainType='E'\" \\\n",
        "  --o-filtered-table \"qiime/table-E.qza\"\n",
        "\n",
        "!qiime composition ancombc \\\n",
        "  --i-table \"qiime/table-E.qza\" \\\n",
        "  --m-metadata-file \"metadata.tsv\" \\\n",
        "  --p-formula Modifier \\\n",
        "  --o-differentials \"qiime/ancombc-E-Modifier-results.qza\"\n",
        "\n",
        "!qiime composition da-barplot \\\n",
        "  --i-data \"qiime/ancombc-E-Modifier-results.qza\" \\\n",
        "  --p-significance-threshold 0.001 \\\n",
        "  --o-visualization \"qiime/ancombc-E-Modifier-results.qzv\"\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Compare Modifier within MainType C\n",
        "# -------------------------------\n",
        "!qiime feature-table filter-samples \\\n",
        "  --i-table \"qiime/table.qza\" \\\n",
        "  --m-metadata-file \"metadata.tsv\" \\\n",
        "  --p-where \"MainType='C'\" \\\n",
        "  --o-filtered-table \"qiime/table-C.qza\"\n",
        "\n",
        "!qiime composition ancombc \\\n",
        "  --i-table \"qiime/table-C.qza\" \\\n",
        "  --m-metadata-file \"metadata.tsv\" \\\n",
        "  --p-formula Modifier \\\n",
        "  --o-differentials \"qiime/ancombc-C-Modifier-results.qza\"\n",
        "\n",
        "!qiime composition da-barplot \\\n",
        "  --i-data \"qiime/ancombc-C-Modifier-results.qza\" \\\n",
        "  --p-significance-threshold 0.001 \\\n",
        "  --o-visualization \"qiime/ancombc-C-Modifier-results.qzv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4275f39f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# ANCOMBC2 APPROACH\n",
        "# -------------------------------\n",
        "# 1. Compare all 6 groups (Group)\n",
        "# Note ancombc2 automatically uses a ONE vs. REST approach for differential analysis\n",
        "# -------------------------------\n",
        "!qiime composition ancombc2 \\\n",
        "  --i-table \"qiime/table.qza\" \\\n",
        "  --m-metadata-file \"metadata.tsv\" \\\n",
        "  --p-fixed-effects-formula Group \\\n",
        "  --o-ancombc2-output \"qiime/ancombc2-Group-results.qza\"\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Compare all 6 groups focusing on MainType (E vs C)\n",
        "# -------------------------------\n",
        "!qiime composition ancombc2 \\\n",
        "  --i-table \"qiime/table.qza\" \\\n",
        "  --m-metadata-file \"metadata.tsv\" \\\n",
        "  --p-fixed-effects-formula MainType \\\n",
        "  --o-ancombc2-output \"qiime/ancombc2-E-vs-C-results.qza\"\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Compare Modifier within MainType E\n",
        "# -------------------------------\n",
        "!qiime feature-table filter-samples \\\n",
        "  --i-table \"qiime/table.qza\" \\\n",
        "  --m-metadata-file \"metadata.tsv\" \\\n",
        "  --p-where \"MainType='E'\" \\\n",
        "  --o-filtered-table \"qiime/table-E.qza\"\n",
        "\n",
        "!qiime composition ancombc2 \\\n",
        "  --i-table \"qiime/table-E.qza\" \\\n",
        "  --m-metadata-file \"metadata.tsv\" \\\n",
        "  --p-fixed-effects-formula Modifier \\\n",
        "  --o-ancombc2-output \"qiime/ancombc2-E-Modifier-results.qza\"\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Compare Modifier within MainType C\n",
        "# -------------------------------\n",
        "!qiime feature-table filter-samples \\\n",
        "  --i-table \"qiime/table.qza\" \\\n",
        "  --m-metadata-file \"metadata.tsv\" \\\n",
        "  --p-where \"MainType='C'\" \\\n",
        "  --o-filtered-table \"qiime/table-C.qza\"\n",
        "\n",
        "!qiime composition ancombc2 \\\n",
        "  --i-table \"qiime/table-C.qza\" \\\n",
        "  --m-metadata-file \"metadata.tsv\" \\\n",
        "  --p-fixed-effects-formula Modifier \\\n",
        "  --o-ancombc2-output \"qiime/ancombc2-C-Modifier-results.qza\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42a74a0e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# To create static plots we have to export the ancombc2 artefacts to jsonl files\n",
        "!qiime tools export \\\n",
        "  --input-path qiime/ancombc2-Group-results.qza \\\n",
        "  --output-path exported/ancombc2-Group-results\n",
        "\n",
        "!qiime tools export \\\n",
        "  --input-path qiime/ancombc2-E-vs-C-results.qza \\\n",
        "  --output-path exported/ancombc2-E-vs-C-results\n",
        "\n",
        "!qiime tools export \\\n",
        "  --input-path qiime/ancombc2-E-Modifier-results.qza \\\n",
        "  --output-path exported/ancombc2-E-Modifier-results\n",
        "\n",
        "!qiime tools export \\\n",
        "  --input-path qiime/ancombc2-C-Modifier-results.qza \\\n",
        "  --output-path exported/ancombc2-C-Modifier-results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48f7b580",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# --- DIRECTORIES TO PROCESS ---\n",
        "# List all your exported ANCOM-BC2 result directories\n",
        "EXPORTED_FOLDERS = [\n",
        "    'exported/ancombc2-Group-results',\n",
        "    'exported/ancombc2-E-vs-C-results',\n",
        "    'exported/ancombc2-E-Modifier-results',\n",
        "    'exported/ancombc2-C-Modifier-results'\n",
        "]\n",
        "# ------------------------------\n",
        "def jsonl_to_tsv(input_filename, output_filename):\n",
        "    \"\"\"\n",
        "    Parses a specific JSONL format (with a schema header) and converts it to TSV.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(input_filename, 'r', encoding='utf-8') as infile:\n",
        "            # 1. Read the schema line (first line)\n",
        "            schema_line = infile.readline()\n",
        "            if not schema_line:\n",
        "                print(\"Error: Input file is empty.\")\n",
        "                return\n",
        "\n",
        "            schema = json.loads(schema_line)\n",
        "            \n",
        "            # Extract the header/field names from the 'fields' array\n",
        "            # This ensures the correct order for the TSV output\n",
        "            header = [field['name'] for field in schema.get('fields', [])]\n",
        "\n",
        "            if not header:\n",
        "                print(\"Error: Could not extract header from the schema.\")\n",
        "                return\n",
        "\n",
        "            # 2. Open the output file for writing TSV\n",
        "            with open(output_filename, 'w', newline='', encoding='utf-8') as outfile:\n",
        "                # Use the csv module with the tab character ('\\t') as the delimiter\n",
        "                writer = csv.writer(outfile, delimiter='\\t')\n",
        "                \n",
        "                # Write the header row\n",
        "                writer.writerow(header)\n",
        "                \n",
        "                # 3. Process the remaining data lines\n",
        "                for line in infile:\n",
        "                    if not line.strip(): # Skip empty lines\n",
        "                        continue\n",
        "                        \n",
        "                    try:\n",
        "                        data_record = json.loads(line)\n",
        "                        \n",
        "                        # Extract values in the order defined by the header\n",
        "                        row_data = [data_record.get(field_name, '') for field_name in header]\n",
        "                        \n",
        "                        # Write the data row\n",
        "                        writer.writerow(row_data)\n",
        "                        \n",
        "                    except json.JSONDecodeError as e:\n",
        "                        print(f\"Skipping malformed JSON line: {line.strip()}. Error: {e}\", file=sys.stderr)\n",
        "                        continue\n",
        "                        \n",
        "        print(f\"Successfully converted {input_filename} to {output_filename}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{input_filename}' was not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        \n",
        "# Run the conversion for all specified directories\n",
        "for folder in EXPORTED_FOLDERS:\n",
        "    # Check if the directory exists before trying to convert\n",
        "    if os.path.isdir(folder):\n",
        "        print(f\"Processing folder: {folder}\")\n",
        "        \n",
        "        # Use glob to find all files ending with .jsonl in the current folder\n",
        "        # The ** is for recursive searching (optional, but good practice if needed)\n",
        "        jsonl_files = glob.glob(os.path.join(folder, '*.jsonl'))\n",
        "\n",
        "        if not jsonl_files:\n",
        "            print(f\"No .jsonl files found in '{folder}'.\")\n",
        "\n",
        "        for input_file in jsonl_files:\n",
        "            # 1. Get the base filename (e.g., 'data_01') without the extension\n",
        "            base_name = os.path.splitext(os.path.basename(input_file))[0]\n",
        "            \n",
        "            # 2. Construct the output TSV filename\n",
        "            # The output file will be placed in the same directory as the input file\n",
        "            output_file = os.path.join(folder, f\"{base_name}.tsv\")\n",
        "            \n",
        "            # 3. Run the conversion function\n",
        "            print(f\"  Converting '{os.path.basename(input_file)}' to '{os.path.basename(output_file)}'...\")\n",
        "            jsonl_to_tsv(input_file, output_file)\n",
        "            \n",
        "    else:\n",
        "        print(f\"Folder not found: '{folder}'. Please check your path.\")\n",
        "\n",
        "print(\"\\n JSONL to .tsv conversion complete. \")\n",
        "print(\"\\n Combining all .tsv files...\")\n",
        "\n",
        "# Column names you expect in each folder (change if yours are named differently)\n",
        "EXPECTED_FILES = [\"diff.tsv\", \"lfc.tsv\", \"p.tsv\", \"q.tsv\", \"se.tsv\", \"W.tsv\", \"passed_ss.tsv\"]\n",
        "\n",
        "for folder in EXPORTED_FOLDERS:\n",
        "    if not os.path.isdir(folder):\n",
        "        print(f\" Folder not found: {folder}\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\n Processing folder: {folder}\")\n",
        "\n",
        "    dfs = {}  # dictionary to store all loaded TSVs\n",
        "    for fname in EXPECTED_FILES:\n",
        "        file_path = os.path.join(folder, fname)\n",
        "        if os.path.exists(file_path):\n",
        "            print(f\"   Found: {fname}\")\n",
        "            dfs[fname.replace(\".tsv\", \"\")] = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
        "        else:\n",
        "            print(f\"   Missing: {fname}\")\n",
        "\n",
        "    if not dfs:\n",
        "        print(\"   No TSV files found — skipping this folder.\")\n",
        "        continue\n",
        "\n",
        "    # Combine all TSVs into one DataFrame\n",
        "    combined = pd.concat(dfs, axis=1)\n",
        "\n",
        "    # Optional: flatten multi-index columns (e.g., diff:ComparisonA)\n",
        "    combined.columns = [f\"{stat}:{col}\" for stat, col in combined.columns]\n",
        "\n",
        "    # Save the final combined file\n",
        "    output_path = os.path.join(folder, \"ancombc2_combined.tsv\")\n",
        "    combined.to_csv(output_path, sep=\"\\t\")\n",
        "    print(f\"   Combined table saved: {output_path}\")\n",
        "\n",
        "print(\"\\n All comparison sets processed. \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f872956e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----------------- CONFIG -----------------\n",
        "EXPORTED_FOLDERS = [\n",
        "    'exported/ancombc2-Group-results',\n",
        "    'exported/ancombc2-E-vs-C-results',\n",
        "    'exported/ancombc2-E-Modifier-results',\n",
        "    'exported/ancombc2-C-Modifier-results'\n",
        "]\n",
        "\n",
        "OUTPUT_DIR = \"differentials_histograms_barplots\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# ----------------- LOAD TAXONOMY -----------------\n",
        "tax_df = pd.read_csv(\"exported/exported-taxonomy/taxonomy.tsv\", sep=\"\\t\", index_col=0)  # index is Feature ID\n",
        "\n",
        "# ----------------- LOOP THROUGH COMPARISONS -----------------\n",
        "for folder in EXPORTED_FOLDERS:\n",
        "    comparison_name = os.path.basename(folder).replace(\"ancombc2-\", \"\").replace(\"-results\", \"\")\n",
        "    print(f\"\\n📊 Processing {comparison_name}\")\n",
        "\n",
        "    combined_path = os.path.join(folder, \"ancombc2_combined.tsv\")\n",
        "    if not os.path.exists(combined_path):\n",
        "        print(f\"❌ Missing {combined_path}, skipping.\")\n",
        "        continue\n",
        "\n",
        "    df = pd.read_csv(combined_path, sep=\"\\t\", index_col=0)\n",
        "\n",
        "    # --- Map Feature IDs to readable taxa names ---\n",
        "    df[\"Taxon\"] = df.index.map(lambda x: tax_df.loc[x, \"Taxon\"] if x in tax_df.index else \"Unassigned\")\n",
        "\n",
        "    # --- Find q-value columns ---\n",
        "    q_cols = [c for c in df.columns if c.startswith(\"q:\")]\n",
        "\n",
        "    # --- Combined q-value histograms ---\n",
        "    thresholds = [0.05, 0.1, 0.2]\n",
        "    if q_cols:\n",
        "        max_cols = 3\n",
        "        n_q = len(q_cols)\n",
        "        n_rows = (n_q + max_cols - 1) // max_cols\n",
        "        n_cols = min(n_q, max_cols)\n",
        "\n",
        "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(6*n_cols, 4*n_rows), squeeze=False)\n",
        "\n",
        "        for i, q_col in enumerate(q_cols):\n",
        "            row = i // max_cols\n",
        "            col = i % max_cols\n",
        "            ax = axes[row, col]\n",
        "\n",
        "            for t in thresholds:\n",
        "                sig_count = (df[q_col] < t).sum()\n",
        "                print(f\"  {q_col}: q < {t:.2f}: {sig_count} taxa\")\n",
        "\n",
        "            sns.histplot(df[q_col].dropna(), bins=40, kde=False, ax=ax)\n",
        "            ax.axvline(0.05, color=\"red\", linestyle=\"--\", label=\"0.05\")\n",
        "            ax.axvline(0.1, color=\"orange\", linestyle=\"--\", label=\"0.10\")\n",
        "            ax.axvline(0.2, color=\"green\", linestyle=\"--\", label=\"0.20\")\n",
        "            ax.set_title(f\"{q_col}\")\n",
        "            ax.set_xlabel(\"q-value\")\n",
        "            ax.set_ylabel(\"Count\")\n",
        "            ax.legend()\n",
        "\n",
        "        # Turn off empty subplots\n",
        "        total_plots = n_rows * n_cols\n",
        "        if total_plots > n_q:\n",
        "            for j in range(n_q, total_plots):\n",
        "                row = j // max_cols\n",
        "                col = j % max_cols\n",
        "                axes[row, col].axis(\"off\")\n",
        "\n",
        "        plt.suptitle(f\"Q-value distributions - {comparison_name}\")\n",
        "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "        plt.savefig(os.path.join(OUTPUT_DIR, f\"{comparison_name}_qval_hist_combined.png\"), dpi=300)\n",
        "        plt.close()\n",
        "        print(f\"✅ Combined Q-value histogram saved: {comparison_name}_qval_hist_combined.png\")\n",
        "\n",
        "    # --- Identify relevant columns for barplot ---\n",
        "    lfc_cols = [c for c in df.columns if c.startswith(\"lfc:\")]\n",
        "    se_cols = [c for c in df.columns if c.startswith(\"se:\")]\n",
        "    import textwrap\n",
        "    # --- Build barplot data ---\n",
        "    barplot_data = []\n",
        "    for lfc_col in lfc_cols:\n",
        "        comparison = lfc_col.replace(\"lfc:\", \"\")\n",
        "        se_col = f\"se:{comparison}\"\n",
        "        q_col = f\"q:{comparison}\"\n",
        "\n",
        "        lfc = df[lfc_col]\n",
        "        se = df[se_col] if se_col in df.columns else pd.Series([None]*len(df), index=df.index)\n",
        "        q = df[q_col] if q_col in df.columns else pd.Series([1.0]*len(df), index=df.index)\n",
        "\n",
        "        sig = q < 0.1\n",
        "        for idx in df.index[sig]:\n",
        "            barplot_data.append({\n",
        "                \"Taxon\": df.loc[idx, \"Taxon\"],  # readable taxon name\n",
        "                \"Comparison\": comparison,\n",
        "                \"lfc\": lfc.loc[idx],\n",
        "                \"se\": se.loc[idx],\n",
        "                \"q\": q.loc[idx]\n",
        "            })\n",
        "\n",
        "    barplot_df = pd.DataFrame(barplot_data)\n",
        "\n",
        "    if not barplot_df.empty:\n",
        "        # Wrap long taxa names at 20 characters\n",
        "        barplot_df[\"Taxon_wrapped\"] = barplot_df[\"Taxon\"].apply(lambda x: \"\\n\".join(textwrap.wrap(x, 20)))\n",
        "\n",
        "        # Adjust figure width based on number of unique taxa\n",
        "        fig_width = max(12, len(barplot_df[\"Taxon\"].unique()) * 0.6)\n",
        "        plt.figure(figsize=(fig_width, 6))\n",
        "\n",
        "        # Create the barplot and get axes object\n",
        "        ax = sns.barplot(\n",
        "            data=barplot_df,\n",
        "            x=\"Taxon_wrapped\", y=\"lfc\", hue=\"Comparison\",\n",
        "            dodge=True, palette=\"coolwarm\", errorbar=None\n",
        "        )\n",
        "\n",
        "        # Add error bars correctly for each bar\n",
        "        for i, row in barplot_df.iterrows():\n",
        "            if pd.notna(row[\"se\"]):\n",
        "                # Find the center x-position of the corresponding bar\n",
        "                bars = [b for b in ax.patches if b.get_height() == row[\"lfc\"] and b.get_x() >= 0]\n",
        "                if bars:\n",
        "                    bar = bars[0]  # take first matching bar\n",
        "                    height = bar.get_height()\n",
        "                    ax.errorbar(\n",
        "                        bar.get_x() + bar.get_width() / 2,  # center of bar\n",
        "                        height,\n",
        "                        yerr=row[\"se\"],\n",
        "                        fmt='none', c='black', capsize=3\n",
        "                    )\n",
        "\n",
        "        plt.xticks(rotation=80, ha=\"right\")\n",
        "        plt.ylabel(\"Log fold change (lfc)\")\n",
        "        plt.title(f\"Differential taxa barplot - {comparison_name} (q < 0.1)\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(OUTPUT_DIR, f\"{comparison_name}_barplot.png\"), dpi=300)\n",
        "        plt.close()\n",
        "        print(f\"✅ Barplot saved for {comparison_name}\")\n",
        "    else:\n",
        "        print(\"⚠️ No significant taxa for barplot (q < 0.1).\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n🎉 Finished! Results in:\", OUTPUT_DIR)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "qiime2-2025.7",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
