{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "40576186",
      "metadata": {},
      "source": [
        "The structure of this notebook goes as follows:\n",
        "1) Load in fastq.gz files, assign relevant information, and cut/trim the raw sequences\n",
        "2) Inspecting the nature and quality of all your samples and decide parameters of further analysis\n",
        "3) Assign taxa with reference classifier, then calculate core diversity metrics\n",
        "4) Visualise alpha/beta diversity\n",
        "5) Calculate permanova/betadisper (which helps explain the result of diversity metrics)\n",
        "6) Identify differential taxa (specific microbes that differ in subsets of your samples)\n",
        "7) Create cladogram"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2c9539a",
      "metadata": {},
      "source": [
        "Section 1 we must create  a \"manifest.tsv\" (which provides paths to the actual sequence files) and a \"metadata.tsv\" (which provides details to the experiment which gives context to each sample in analysis). These two files will guide the entire analysis pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f86f23fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import all necessary packages\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import biom\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "from matplotlib.patches import Ellipse\n",
        "import glob\n",
        "import csv\n",
        "import json\n",
        "import qiime2\n",
        "import seaborn as sns\n",
        "from skbio.stats.ordination import OrdinationResults\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "aaf8b364",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Manifest written to: /home/patwuch/projects/microbiome/experiments/yang/manifest.tsv\n",
            "Samples included: 20\n",
            "   sampleid                          forward-absolute-filepath  \\\n",
            "0  PD_O_BK2  /home/patwuch/projects/microbiome/experiments/...   \n",
            "1  PD_O_BK4  /home/patwuch/projects/microbiome/experiments/...   \n",
            "2  PD_O_BU2  /home/patwuch/projects/microbiome/experiments/...   \n",
            "3   PD_O_G1  /home/patwuch/projects/microbiome/experiments/...   \n",
            "4  PD_Sh_G1  /home/patwuch/projects/microbiome/experiments/...   \n",
            "\n",
            "                           reverse-absolute-filepath  \n",
            "0  /home/patwuch/projects/microbiome/experiments/...  \n",
            "1  /home/patwuch/projects/microbiome/experiments/...  \n",
            "2  /home/patwuch/projects/microbiome/experiments/...  \n",
            "3  /home/patwuch/projects/microbiome/experiments/...  \n",
            "4  /home/patwuch/projects/microbiome/experiments/...  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Get notebook directory\n",
        "project_dir = Path(os.getcwd())\n",
        "\n",
        "# Define input/output dirs\n",
        "raw_dir = project_dir / \"raw\"\n",
        "qiime_dir = project_dir / 'qiime'\n",
        "manifest_file = project_dir / \"manifest.tsv\"\n",
        "\n",
        "# Recursively list all FASTQ files\n",
        "fastqs = sorted(raw_dir.rglob(\"*.fq.gz\"))\n",
        "\n",
        "if not fastqs:\n",
        "    raise FileNotFoundError(f\"No FASTQ files found in {raw_dir}\")\n",
        "\n",
        "# Helper: get parent folder name as sampleid\n",
        "def extract_sample_name(fname: Path) -> str:\n",
        "    \"\"\"\n",
        "    Use the parent folder name of the FASTQ file as the sample ID.\n",
        "    \"\"\"\n",
        "    return fname.parent.name\n",
        "\n",
        "# Group by sample name (folder containing the reads)\n",
        "samples = {}\n",
        "for f in fastqs:\n",
        "    sample = extract_sample_name(f)\n",
        "    if sample not in samples:\n",
        "        samples[sample] = {\"R1\": None, \"R2\": None}\n",
        "\n",
        "    if re.search(r\"(R1|_1)\\.f(ast)?q\\.gz$\", f.name):\n",
        "        samples[sample][\"R1\"] = f.resolve()\n",
        "    elif re.search(r\"(R2|_2)\\.f(ast)?q\\.gz$\", f.name):\n",
        "        samples[sample][\"R2\"] = f.resolve()\n",
        "\n",
        "# Build manifest DataFrame\n",
        "records = []\n",
        "for sample, files in samples.items():\n",
        "    if files[\"R1\"] and files[\"R2\"]:\n",
        "        records.append({\n",
        "            \"sampleid\": sample,\n",
        "            \"forward-absolute-filepath\": str(files[\"R1\"]),\n",
        "            \"reverse-absolute-filepath\": str(files[\"R2\"]),\n",
        "        })\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Skipping {sample}: missing R1 or R2\")\n",
        "\n",
        "manifest = pd.DataFrame(records)\n",
        "\n",
        "# Save manifest\n",
        "manifest.to_csv(manifest_file, sep=\"\\t\", index=False)\n",
        "\n",
        "print(f\"‚úÖ Manifest written to: {manifest_file.resolve()}\")\n",
        "print(f\"Samples included: {len(manifest)}\")\n",
        "print(manifest.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dbb1e9c",
      "metadata": {},
      "source": [
        "Section 2 we start actually working with our sequences. We will inspect quality, denoise, truncate, and inspect again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mImported manifest.tsv as PairedEndFastqManifestPhred33V2 to qiime/demux.qza\u001b[0m\n",
            "\u001b[?25h\u001b[0m"
          ]
        }
      ],
      "source": [
        "# This imports the fastq files and creates a QIIME2 artifact\n",
        "!mkdir -p qiime\n",
        "# Select the manifest \n",
        "!qiime tools import \\\n",
        "  --type 'SampleData[PairedEndSequencesWithQuality]' \\\n",
        "  --input-format PairedEndFastqManifestPhred33V2 \\\n",
        "  --input-path \"manifest.tsv\" \\\n",
        "  --output-path \"qiime/demux.qza\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fd4e685c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved Visualization to: qiime/demux.qzv\u001b[0m\n",
            "\u001b[?25h\u001b[0m"
          ]
        }
      ],
      "source": [
        "# This creates a qiime2 visualisation artefact with which you can check on QIIME2 View the quality of the reads\n",
        "# Based on the QC plots, you can decide the length at which to trim the reads in the next step\n",
        "!qiime demux summarize \\\n",
        "    --i-data \"qiime/demux.qza\" \\\n",
        "    --o-visualization \"qiime/demux.qzv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "315e4e72",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved FeatureTable[Frequency] to: qiime/table.qza\u001b[0m\n",
            "\u001b[32mSaved FeatureData[Sequence] to: qiime/rep-seqs.qza\u001b[0m\n",
            "\u001b[32mSaved SampleData[DADA2Stats] to: qiime/stats.qza\u001b[0m\n",
            "\u001b[?25h\u001b[0m"
          ]
        }
      ],
      "source": [
        "# DADA2 is a popular denoising algorithm that corrects amplicon errors while also removing chimeras\n",
        "# It will return artefacts which can be converted to visualisation to see if we trimmed appropriately\n",
        "!qiime dada2 denoise-paired \\\n",
        "    --i-demultiplexed-seqs \"qiime/demux.qza\" \\\n",
        "    --p-trim-left-f 10 \\\n",
        "    --p-trim-left-r 10 \\\n",
        "    --p-trunc-len-f 260 \\\n",
        "    --p-trunc-len-r 220 \\\n",
        "    --o-table \"qiime/table.qza\" \\\n",
        "    --o-representative-sequences \"qiime/rep-seqs.qza\" \\\n",
        "    --o-denoising-stats \"qiime/stats.qza\" \\\n",
        "    --p-n-threads 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved Visualization to: qiime/table.qzv\u001b[0m\n",
            "\u001b[?25h\u001b[0m/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved Visualization to: qiime/rep-seqs.qzv\u001b[0m\n",
            "\u001b[?25h\u001b[0m/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved Visualization to: qiime/stats.qzv\u001b[0m\n",
            "\u001b[?25h\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Now we convert the dada2 artefacts in the previous cell to visualisations\n",
        "# If it passes the QC, we can proceed to assign taxonomy\n",
        "!qiime feature-table summarize \\\n",
        "    --i-table \"qiime/table.qza\" \\\n",
        "    --o-visualization \"qiime/table.qzv\" \\\n",
        "    --m-sample-metadata-file \"metadata.tsv\"\n",
        "\n",
        "!qiime feature-table tabulate-seqs \\\n",
        "    --i-data \"qiime/rep-seqs.qza\" \\\n",
        "    --o-visualization \"qiime/rep-seqs.qzv\"\n",
        "\n",
        "!qiime metadata tabulate \\\n",
        "    --m-input-file \"qiime/stats.qza\" \\\n",
        "    --o-visualization \"qiime/stats.qzv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mQIIME is caching your current deployment for improved performance. This may take a few moments and should only happen once per deployment.\u001b[0m\n",
            "/home/patwuch/miniforge3/envs/q2-amplicon-core-2025.10/lib/python3.10/site-packages/unifrac/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved FeatureData[Taxonomy] to: qiime/taxonomy.qza\u001b[0m\n",
            "\u001b[?25h\u001b[0m/home/patwuch/miniforge3/envs/q2-amplicon-core-2025.10/lib/python3.10/site-packages/unifrac/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved Visualization to: qiime/taxonomy.qzv\u001b[0m\n",
            "\u001b[?25h\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Point this to your actual classifier\n",
        "classifier_path = \"/home/patwuch/projects/microbiome/reference/gg_12_10_primer_region-classifier.qza\"\n",
        "\n",
        "!qiime feature-classifier classify-sklearn \\\n",
        "    --i-classifier {classifier_path} \\\n",
        "    --i-reads \"qiime/rep-seqs.qza\" \\\n",
        "    --o-classification \"qiime/taxonomy.qza\"\n",
        "\n",
        "# Exhaustive list of taxonomic assignments with confidence scores\n",
        "!qiime metadata tabulate \\\n",
        "    --m-input-file \"qiime/taxonomy.qza\" \\\n",
        "    --o-visualization \"qiime/taxonomy.qzv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/patwuch/miniforge3/envs/q2-amplicon-core-2025.10/lib/python3.10/site-packages/unifrac/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved Visualization to: qiime/taxa-bar-plots.qzv\u001b[0m\n",
            "\u001b[?25h\u001b[0m\u001b[31m\u001b[1mError: QIIME 2 has no plugin/command named 'krona'.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Taxa bar plots are a common way to visualise taxonomic composition across samples\n",
        "!qiime taxa barplot \\\n",
        "    --i-table \"qiime/table.qza\" \\\n",
        "    --i-taxonomy \"qiime/taxonomy.qza\" \\\n",
        "    --m-metadata-file \"metadata.tsv\" \\\n",
        "    --o-visualization \"qiime/taxa-bar-plots.qzv\"\n",
        "\n",
        "# Krona is a helpful way to interactively explore taxonomic composition\n",
        "# But it is not great for static figures in publications\n",
        "!qiime krona collapse-and-plot \\\n",
        "    --i-table \"qiime/table.qza\" \\\n",
        "    --i-taxonomy \"qiime/taxonomy.qza\" \\\n",
        "    --o-krona-plot \"qiime/krona.qzv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "002bf6e3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/patwuch/miniforge3/envs/q2-amplicon-core-2025.10/lib/python3.10/site-packages/unifrac/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mExported qiime/table.qza as BIOMV210DirFmt to directory exported/exported-feature-table\u001b[0m\n",
            "\u001b[?25h\u001b[0m/home/patwuch/miniforge3/envs/q2-amplicon-core-2025.10/lib/python3.10/site-packages/unifrac/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mExported qiime/taxonomy.qza as TSVTaxonomyDirectoryFormat to directory exported/exported-taxonomy\u001b[0m\n",
            "\u001b[?25h\u001b[0m"
          ]
        }
      ],
      "source": [
        "# If you want static plots of alpha and beta diversity as png, you must use the following commands\n",
        "# These export qiime artefacts into more standard bioinformatics file formats\n",
        "!qiime tools export \\\n",
        "  --input-path qiime/table.qza \\\n",
        "  --output-path exported/exported-feature-table\n",
        "\n",
        "!qiime tools export \\\n",
        "  --input-path qiime/taxonomy.qza \\\n",
        "  --output-path exported/exported-taxonomy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "1b1a6b6c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Then we convert .biom to .tsv (tsv is the most generalist format--which means it'll be easy to pass to R)\n",
        "!biom convert \\\n",
        "  -i exported/exported-feature-table/feature-table.biom \\\n",
        "  -o exported/exported-feature-table/table.from_biom.tsv \\\n",
        "  --to-tsv\n",
        "# Same goes for taxonomy, "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6b012c1d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Kingdom...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2564027/1625060123.py:121: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
            "  df_tax = df.groupby(taxonomy[tax_level], axis=1).sum()\n",
            "/tmp/ipykernel_2564027/1625060123.py:134: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
            "  cmap = cm.get_cmap('tab20', n_colors)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Phylum...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2564027/1625060123.py:121: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
            "  df_tax = df.groupby(taxonomy[tax_level], axis=1).sum()\n",
            "/tmp/ipykernel_2564027/1625060123.py:134: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
            "  cmap = cm.get_cmap('tab20', n_colors)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Class...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2564027/1625060123.py:121: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
            "  df_tax = df.groupby(taxonomy[tax_level], axis=1).sum()\n",
            "/tmp/ipykernel_2564027/1625060123.py:134: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
            "  cmap = cm.get_cmap('tab20', n_colors)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Order...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2564027/1625060123.py:121: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
            "  df_tax = df.groupby(taxonomy[tax_level], axis=1).sum()\n",
            "/tmp/ipykernel_2564027/1625060123.py:134: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
            "  cmap = cm.get_cmap('tab20', n_colors)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Family...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2564027/1625060123.py:121: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
            "  df_tax = df.groupby(taxonomy[tax_level], axis=1).sum()\n",
            "/tmp/ipykernel_2564027/1625060123.py:134: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
            "  cmap = cm.get_cmap('tab20', n_colors)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Genus...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2564027/1625060123.py:121: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
            "  df_tax = df.groupby(taxonomy[tax_level], axis=1).sum()\n",
            "/tmp/ipykernel_2564027/1625060123.py:134: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
            "  cmap = cm.get_cmap('tab20', n_colors)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import biom\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "\n",
        "output_dir = \"taxa_barplots\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ===========================\n",
        "# USER SETTINGS\n",
        "# ===========================\n",
        "feature_table_biom = \"exported/exported-feature-table/feature-table.biom\"\n",
        "taxonomy_tsv = \"exported/exported-taxonomy/taxonomy.tsv\"\n",
        "top_n = 20            # Number of taxa to show in legend\n",
        "\n",
        "# ===========================\n",
        "# LOAD DATA\n",
        "# ===========================\n",
        "table = biom.load_table(feature_table_biom)\n",
        "df = pd.DataFrame(table.matrix_data.toarray().T, \n",
        "                  index=table.ids(axis='sample'), \n",
        "                  columns=table.ids(axis='observation'))\n",
        "\n",
        "taxonomy = pd.read_csv(taxonomy_tsv, sep='\\t', index_col=0)\n",
        "\n",
        "# üëá FIX FOR AttributeError: 'float' object has no attribute 'lower'\n",
        "# Ensure the Taxon column is treated as a string and missing values are empty strings.\n",
        "taxonomy['Taxon'] = taxonomy['Taxon'].astype(str).fillna('').str.strip()\n",
        "\n",
        "level_dict = {\n",
        "    \"Kingdom\": 0,\n",
        "    \"Phylum\": 1,\n",
        "    \"Class\": 2,\n",
        "    \"Order\": 3,\n",
        "    \"Family\": 4,\n",
        "    \"Genus\": 5,\n",
        "}\n",
        "\n",
        "# Define the order of levels for easy lookup\n",
        "LEVEL_NAMES = list(level_dict.keys())\n",
        "LEVEL_INDICES = list(level_dict.values())\n",
        "\n",
        "# Helper function to find the highest-level assignment for a feature\n",
        "def relabel_unassigned_taxa(row, current_level_index):\n",
        "    \"\"\"\n",
        "    Looks up the next available, higher taxonomic level for unassigned features,\n",
        "    safely handling taxonomy strings that are shorter than 6 levels.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Safely split the taxonomy string and pad with 'Unassigned' if needed.\n",
        "    taxa_list = [t.strip() for t in row['Taxon'].split(';')]\n",
        "    # Ensure the list is padded up to the maximum number of levels (6)\n",
        "    while len(taxa_list) < len(LEVEL_NAMES): \n",
        "        taxa_list.append(\"Unassigned\")\n",
        "        \n",
        "    # 1. Get the current level assignment\n",
        "    current_label = taxa_list[current_level_index]\n",
        "    \n",
        "    # 2. Check if the current label is unassigned (or similar)\n",
        "    if 'unassigned' in current_label.lower() or current_label.strip() == '':\n",
        "        # 3. Iterate through higher levels (from current_level_index - 1 down to 0)\n",
        "        for i in range(current_level_index - 1, -1, -1):\n",
        "            higher_level_label = taxa_list[i]\n",
        "            \n",
        "            # 4. If a higher level is assigned, use it as the prefix\n",
        "            if 'unassigned' not in higher_level_label.lower() and higher_level_label.strip() != '':\n",
        "                higher_level_name = LEVEL_NAMES[i]\n",
        "                # Format: \"Unassigned ({HigherLevel} {HigherLabel})\"\n",
        "                return f\"Unassigned ({higher_level_name} {higher_level_label})\"\n",
        "        \n",
        "        # 5. If no higher level is assigned (all are unassigned), return a generic label\n",
        "        return \"Unassigned (All)\"\n",
        "    \n",
        "    # 6. If the current label is not unassigned, return it as is\n",
        "    return current_label\n",
        "\n",
        "\n",
        "# ===========================\n",
        "# LOOP THROUGH TAXONOMIC LEVELS\n",
        "# ===========================\n",
        "for tax_level, level_index in level_dict.items():\n",
        "    print(f\"Processing {tax_level}...\")\n",
        "\n",
        "    # --- LOGIC FOR RELABELING ---\n",
        "    if tax_level != \"Kingdom\": # Kingdom level is the highest, no higher level to check\n",
        "        # Apply the relabeling function to create the new, more descriptive tax column\n",
        "        taxonomy[tax_level] = taxonomy.apply(\n",
        "            relabel_unassigned_taxa, \n",
        "            axis=1, \n",
        "            current_level_index=level_index\n",
        "        )\n",
        "    else:\n",
        "        # Kingdom level is simpler: just get the label and handle Unassigned\n",
        "        # We rely on the padding in the function below to ensure safe access,\n",
        "        # but for Kingdom we can still use the simpler logic for readability.\n",
        "        taxonomy[tax_level] = taxonomy['Taxon'].str.split(';').str[level_index].str.strip().fillna(\"Unassigned\")\n",
        "        taxonomy[tax_level] = taxonomy[tax_level].apply(\n",
        "            lambda x: \"Unassigned (All)\" if 'unassigned' in x.lower() or x.strip() == '' else x\n",
        "        )\n",
        "    \n",
        "    # --- Special case for Genus (Family|Genus) still needed ---\n",
        "    if tax_level == \"Genus\":\n",
        "        # Extract the Family name. We use the safe list access within a lambda.\n",
        "        taxonomy[\"Family_prefix\"] = taxonomy['Taxon'].apply(\n",
        "            lambda x: ([t.strip() for t in x.split(';')] + ['Unassigned'] * 6)[level_dict[\"Family\"]]\n",
        "        )\n",
        "        \n",
        "        # We need the *relabelled* genus for the second part of the string\n",
        "        # Combine Family prefix with the (potentially relabelled) Genus name\n",
        "        taxonomy[tax_level] = taxonomy.apply(\n",
        "            lambda row: f\"{row['Family_prefix']}|{row[tax_level]}\" \n",
        "                        if 'unassigned' not in row['Family_prefix'].lower() and row['Family_prefix'].strip() != ''\n",
        "                        else row[tax_level], # If Family is unassigned, just use the Genus label\n",
        "            axis=1\n",
        "        )\n",
        "    # -----------------------------------------------------------\n",
        "\n",
        "    # Aggregate counts by taxonomic level\n",
        "    df_tax = df.groupby(taxonomy[tax_level], axis=1).sum()\n",
        "    df_tax_norm = df_tax.div(df_tax.sum(axis=1), axis=0)\n",
        "\n",
        "    # Identify top N taxa by mean relative abundance\n",
        "    mean_abundance = df_tax_norm.mean(axis=0)\n",
        "    top_taxa = mean_abundance.sort_values(ascending=False).head(top_n).index\n",
        "\n",
        "    # Prepare dataframe for plotting\n",
        "    df_top = df_tax_norm[top_taxa].copy()\n",
        "    df_top['Other'] = df_tax_norm.drop(columns=top_taxa, errors='ignore').sum(axis=1)\n",
        "\n",
        "    # Color map\n",
        "    n_colors = df_top.shape[1]\n",
        "    cmap = cm.get_cmap('tab20', n_colors)\n",
        "    colors = [cmap(i) for i in range(n_colors)]\n",
        "\n",
        "    # Plot manually stacked bars\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    bottom = np.zeros(df_top.shape[0])\n",
        "    for i, col in enumerate(df_top.columns):\n",
        "        ax.bar(\n",
        "            df_top.index,\n",
        "            df_top[col],\n",
        "            bottom=bottom,\n",
        "            color=colors[i],\n",
        "            label=col,\n",
        "            width=0.8,\n",
        "            edgecolor=\"none\",\n",
        "            linewidth=0,\n",
        "            antialiased=False\n",
        "        )\n",
        "        bottom += df_top[col].values\n",
        "\n",
        "    # Axis labels and title\n",
        "    ax.set_ylabel(\"Relative abundance\")\n",
        "    ax.set_xlabel(\"Samples\")\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.title(f\"Relative abundance at {tax_level} level\")\n",
        "\n",
        "    # Legend in descending abundance order\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    handles, labels = handles[::-1], labels[::-1]\n",
        "    ax.legend(\n",
        "        handles, labels,\n",
        "        bbox_to_anchor=(1.05, 1),\n",
        "        loc='upper left',\n",
        "        fontsize=8,\n",
        "        title=\"Taxa\",\n",
        "        title_fontsize=9,\n",
        "        frameon=False\n",
        "    )\n",
        "\n",
        "    plt.tight_layout()\n",
        "    output_png = f\"{output_dir}/taxa_barplot_{tax_level}.png\"\n",
        "    plt.savefig(output_png, dpi=300, bbox_inches=\"tight\")\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e90ae39d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/patwuch/miniforge3/envs/q2-amplicon-gg-2025.10/lib/python3.10/site-packages/unifrac/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved FeatureTable[Frequency] to: qiime/gg-table.qza\u001b[0m\n",
            "\u001b[32mSaved FeatureData[Sequence] to: qiime/gg-rep-seqs.qza\u001b[0m\n",
            "\u001b[?25h\u001b[0m"
          ]
        }
      ],
      "source": [
        "# builds greengenes2 phylogenetic tree\n",
        "# THIS MUST BE RUN IN THE Qiime2 Greengenes2 ENVIRONMENT or else it will break core dependencies for other parts of the pipeline\n",
        "# Greengenes2 provides a either v4 or non-v4 backbone for phylogenetic placement, which can essentially be used for any 16S region\n",
        "# Unless you have too much computation power  go train a new tree then lol\n",
        "\n",
        "!qiime greengenes2 non-v4-16s \\\n",
        "    --i-table qiime/table.qza \\\n",
        "    --i-sequences qiime/rep-seqs.qza \\\n",
        "    --i-backbone /home/patwuch/projects/microbiome/reference/Greengenes2/2024.09.backbone.full-length.fna.qza \\\n",
        "    --p-threads 6 \\\n",
        "    --o-mapped-table qiime/gg-table.qza \\\n",
        "    --o-representatives qiime/gg-rep-seqs.qza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0dd5e555",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/patwuch/miniforge3/envs/q2-amplicon-core-2025.10/lib/python3.10/site-packages/unifrac/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved FeatureTable[Frequency] to: qiime/rarefied_table.qza\u001b[0m\n",
            "\u001b[?25h\u001b[0m/home/patwuch/miniforge3/envs/q2-amplicon-core-2025.10/lib/python3.10/site-packages/unifrac/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved SampleData[AlphaDiversity] to: core-metrics-results/shannon_vector.qza\u001b[0m\n",
            "\u001b[?25h\u001b[0m/home/patwuch/miniforge3/envs/q2-amplicon-core-2025.10/lib/python3.10/site-packages/unifrac/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved SampleData[AlphaDiversity] to: core-metrics-results/chao1_vector.qza\u001b[0m\n",
            "\u001b[?25h\u001b[0m/home/patwuch/miniforge3/envs/q2-amplicon-core-2025.10/lib/python3.10/site-packages/unifrac/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved SampleData[AlphaDiversity] to: core-metrics-results/simpson_vector.qza\u001b[0m\n",
            "\u001b[?25h\u001b[0m/home/patwuch/miniforge3/envs/q2-amplicon-core-2025.10/lib/python3.10/site-packages/unifrac/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved SampleData[AlphaDiversity] to: core-metrics-results/evenness_vector.qza\u001b[0m\n",
            "\u001b[?25h\u001b[0m"
          ]
        }
      ],
      "source": [
        "!rm -rf core-metrics-results\n",
        "!mkdir core-metrics-results\n",
        "\n",
        "\n",
        "# First we must rarefy the feature table to an even sampling depth\n",
        "!qiime feature-table rarefy \\\n",
        "  --i-table qiime/gg-table.qza \\\n",
        "  --p-sampling-depth 44645 \\\n",
        "  --o-rarefied-table qiime/rarefied_table.qza\n",
        "\n",
        "# Shannon\n",
        "!qiime diversity alpha \\\n",
        "  --i-table qiime/rarefied_table.qza \\\n",
        "  --p-metric shannon \\\n",
        "  --o-alpha-diversity core-metrics-results/shannon_vector.qza\n",
        "\n",
        "# Chao1\n",
        "!qiime diversity alpha \\\n",
        "  --i-table qiime/rarefied_table.qza \\\n",
        "  --p-metric chao1 \\\n",
        "  --o-alpha-diversity core-metrics-results/chao1_vector.qza\n",
        "\n",
        "# Simpson\n",
        "!qiime diversity alpha \\\n",
        "  --i-table qiime/rarefied_table.qza \\\n",
        "  --p-metric simpson \\\n",
        "  --o-alpha-diversity core-metrics-results/simpson_vector.qza\n",
        "\n",
        "# Evenness\n",
        "!qiime diversity alpha \\\n",
        "  --i-table qiime/rarefied_table.qza \\\n",
        "  --p-metric pielou_e \\\n",
        "  --o-alpha-diversity core-metrics-results/evenness_vector.qza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee0069f9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31m\u001b[1mError: QIIME 2 plugin 'diversity' has no action 'check-tree'.\u001b[0m\n",
            "/home/patwuch/miniforge3/envs/q2-amplicon-core-2025.10/lib/python3.10/site-packages/unifrac/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[31m\u001b[1mPlugin error from diversity:\n",
            "\n",
            "  Command '['ssu', '-i', '/tmp/qiime2/root/data/7ad98397-dfa6-49c3-9497-6126da3a205b/data/feature-table.biom', '-t', '/tmp/qiime2/root/data/52e0fb90-d576-4f77-a07e-8f0b9dd78dda/data/tree.nwk', '-m', 'unweighted', '-o', '/tmp/qiime2/root/processes/2685807-1762243564.03@root/tmp/q2-OutPath-owvqkimz']' died with <Signals.SIGABRT: 6>.\n",
            "\n",
            "Debug info has been saved to /tmp/qiime2-q2cli-err-0hx7iisn.log\u001b[0m\n",
            "\u001b[?25h\u001b[0m/home/patwuch/miniforge3/envs/q2-amplicon-core-2025.10/lib/python3.10/site-packages/unifrac/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[31m\u001b[1mPlugin error from diversity:\n",
            "\n",
            "  Command '['ssu', '-i', '/tmp/qiime2/root/data/7ad98397-dfa6-49c3-9497-6126da3a205b/data/feature-table.biom', '-t', '/tmp/qiime2/root/data/52e0fb90-d576-4f77-a07e-8f0b9dd78dda/data/tree.nwk', '-m', 'weighted_unnormalized', '-o', '/tmp/qiime2/root/processes/2686695-1762243753.67@root/tmp/q2-OutPath-57vifl_0']' died with <Signals.SIGABRT: 6>.\n",
            "\n",
            "Debug info has been saved to /tmp/qiime2-q2cli-err-n5bstx3t.log\u001b[0m\n",
            "\u001b[?25h\u001b[0m/home/patwuch/miniforge3/envs/q2-amplicon-core-2025.10/lib/python3.10/site-packages/unifrac/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\n",
            "Aborted!\n",
            "\u001b[0m^C\n",
            "/home/patwuch/miniforge3/envs/q2-amplicon-core-2025.10/lib/python3.10/site-packages/unifrac/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n"
          ]
        }
      ],
      "source": [
        "phylogeny_path = \"/home/patwuch/projects/microbiome/reference/Greengenes2/2024.09.phylogeny.id.nwk.qza\"\n",
        "\n",
        "!qiime diversity check-tree \\\n",
        "  --i-table qiime/rarefied-table.qza \\\n",
        "  --i-phylogeny \"$phylogeny_path\"\n",
        "# Now for beta diversity\n",
        "# Jaccard\n",
        "# !qiime diversity beta \\\n",
        "#   --i-table qiime/rarefied_table.qza \\\n",
        "#   --p-metric jaccard \\\n",
        "#   --o-distance-matrix core-metrics-results/jaccard_distance_matrix.qza\n",
        "\n",
        "\n",
        "# # Bray-Curtis\n",
        "# !qiime diversity beta \\\n",
        "#   --i-table qiime/rarefied_table.qza \\\n",
        "#   --p-metric braycurtis \\\n",
        "#   --o-distance-matrix core-metrics-results/bray_curtis_distance_matrix.qza\n",
        "\n",
        "# !qiime diversity pcoa \\\n",
        "#   --i-distance-matrix core-metrics-results/bray_curtis_distance_matrix.qza \\\n",
        "#   --o-pcoa core-metrics-results/bray_curtis_pcoa_results.qza\n",
        "# !qiime diversity pcoa \\\n",
        "#   --i-distance-matrix core-metrics-results/jaccard_distance_matrix.qza \\\n",
        "#   --o-pcoa core-metrics-results/jaccard_pcoa_results.qza\n",
        "\n",
        "\n",
        "#   BETA DIVERSITY (Phylogenetic - using the full Greengenes2 tree because we used SEPP on the non-v4 backbone too)\n",
        "!qiime diversity beta-phylogenetic \\\n",
        "  --i-table qiime/rarefied_table.qza \\\n",
        "  --i-phylogeny /home/patwuch/projects/microbiome/reference/Greengenes2/2024.09.phylogeny.id.nwk.qza\\\n",
        "  --p-metric unweighted_unifrac \\\n",
        "  --o-distance-matrix core-metrics-results/unweighted_unifrac_distance_matrix.qza \\\n",
        "  --p-threads 1\n",
        "\n",
        "# BETA DIVERSITY (Phylogenetic - using the Greengenes2 tree)\n",
        "!qiime diversity beta-phylogenetic \\\n",
        "  --i-table qiime/rarefied_table.qza \\\n",
        "  --i-phylogeny \"$phylogeny_path\" \\\n",
        "  --p-metric weighted_unifrac \\\n",
        "  --o-distance-matrix core-metrics-results/weighted_unifrac_distance_matrix.qza \\\n",
        "  --p-threads 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "!qiime diversity pcoa \\\n",
        "  --i-distance-matrix core-metrics-results/unweighted_unifrac_distance_matrix.qza \\\n",
        "  --o-pcoa core-metrics-results/unweighted_unifrac_pcoa_results.qza\n",
        "!qiime diversity pcoa \\\n",
        "  --i-distance-matrix core-metrics-results/weighted_unifrac_distance_matrix.qza \\\n",
        "  --o-pcoa core-metrics-results/weighted_unifrac_pcoa_results.qza\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1462e9d5",
      "metadata": {},
      "source": [
        "Section 4 we create alpha and beta diversity visualisations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b912bb61",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'qiime2' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ---- Load alpha diversity artifacts ----\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m shannon \u001b[38;5;241m=\u001b[39m \u001b[43mqiime2\u001b[49m\u001b[38;5;241m.\u001b[39mArtifact\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcore-metrics-results/shannon_vector.qza\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mview(pd\u001b[38;5;241m.\u001b[39mSeries)\n\u001b[1;32m      3\u001b[0m evenness \u001b[38;5;241m=\u001b[39m qiime2\u001b[38;5;241m.\u001b[39mArtifact\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcore-metrics-results/evenness_vector.qza\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mview(pd\u001b[38;5;241m.\u001b[39mSeries)\n\u001b[1;32m      4\u001b[0m chao1 \u001b[38;5;241m=\u001b[39m qiime2\u001b[38;5;241m.\u001b[39mArtifact\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcore-metrics-results/chao1_vector.qza\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mview(pd\u001b[38;5;241m.\u001b[39mSeries)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'qiime2' is not defined"
          ]
        }
      ],
      "source": [
        "# ---- Load alpha diversity artifacts ----\n",
        "shannon = qiime2.Artifact.load(\"core-metrics-results/shannon_vector.qza\").view(pd.Series)\n",
        "evenness = qiime2.Artifact.load(\"core-metrics-results/evenness_vector.qza\").view(pd.Series)\n",
        "chao1 = qiime2.Artifact.load(\"core-metrics-results/chao1_vector.qza\").view(pd.Series)\n",
        "simpson = qiime2.Artifact.load(\"core-metrics-results/simpson_vector.qza\").view(pd.Series)\n",
        "\n",
        "# ---- Load metadata ----\n",
        "metadata = pd.read_csv(\"metadata.tsv\", sep=\"\\t\", index_col=0)\n",
        "\n",
        "# ---- Combine alpha diversity into one DataFrame ----\n",
        "alpha_df = pd.concat([\n",
        "    shannon.rename(\"Shannon\"),\n",
        "    evenness.rename(\"Evenness\"),\n",
        "    chao1.rename(\"Chao1\"),\n",
        "    simpson.rename(\"Simpson\")\n",
        "], axis=1)\n",
        "\n",
        "# ---- Merge alpha diversity with metadata ----\n",
        "merged = alpha_df.join(metadata)\n",
        "merged['Group'] = merged['Group'].str.strip()\n",
        "\n",
        "# ---- Output folder ----\n",
        "os.makedirs(\"alpha_diversity_plots\", exist_ok=True)\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# ---- Define comparisons in flexible style ----\n",
        "comparisons = [\n",
        "    (\"Group\", None),                # all groups\n",
        "    (\"Butyrate\", None),  # only C subgroups\n",
        "    (\"Disease\", None)      # only E subgroups\n",
        "]\n",
        "\n",
        "# ---- Function to plot alpha diversity ----\n",
        "def plot_alpha_diversity(df, x_col, levels=None, title=None, outfile=None):\n",
        "    # Subset if levels provided\n",
        "    if levels is not None:\n",
        "        df = df[df[x_col].isin(levels)]\n",
        "    \n",
        "    # Melt for seaborn\n",
        "    melted = df.melt(\n",
        "        id_vars=[x_col],\n",
        "        value_vars=[\"Shannon\", \"Evenness\", \"Chao1\", \"Simpson\"],\n",
        "        var_name=\"Metric\",\n",
        "        value_name=\"Diversity\"\n",
        "    )\n",
        "    \n",
        "    # Plot\n",
        "    g = sns.catplot(\n",
        "        data=melted,\n",
        "        x=x_col, y=\"Diversity\",\n",
        "        col=\"Metric\",\n",
        "        kind=\"box\",\n",
        "        col_wrap=2,\n",
        "        sharey=False,\n",
        "        height=4, aspect=1.2\n",
        "    )\n",
        "    g.map_dataframe(sns.stripplot, x=x_col, y=\"Diversity\", color=\"black\", alpha=0.5)\n",
        "    plt.subplots_adjust(top=0.85)\n",
        "    \n",
        "    if title:\n",
        "        g.figure.suptitle(title)\n",
        "    if outfile:\n",
        "        g.savefig(outfile, dpi=300, bbox_inches=\"tight\")\n",
        "    plt.close(g.fig)\n",
        "\n",
        "# ---- Loop over comparisons ----\n",
        "for x_col, levels in comparisons:\n",
        "    name = f\"{x_col}_{'_'.join(levels) if levels else 'all'}\"\n",
        "    title = f\"Alpha Diversity - {name.replace('_', ' ')}\"\n",
        "    outfile = f\"alpha_diversity_plots/alpha_diversity_{name}.png\"\n",
        "    \n",
        "    plot_alpha_diversity(\n",
        "        df=merged,\n",
        "        x_col=x_col,\n",
        "        levels=levels,\n",
        "        title=title,\n",
        "        outfile=outfile\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Ellipse\n",
        "from qiime2 import Artifact\n",
        "from skbio.stats.ordination import OrdinationResults\n",
        "\n",
        "# Load PCoA results\n",
        "pcoa_results = {\n",
        "    \"Bray-Curtis\": Artifact.load(\"core-metrics-results/bray_curtis_pcoa_results.qza\").view(OrdinationResults),\n",
        "    \"Jaccard\": Artifact.load(\"core-metrics-results/jaccard_pcoa_results.qza\").view(OrdinationResults),\n",
        "    \"Weighted Unifrac\": Artifact.load(\"core-metrics-results/weighted_unifrac_pcoa_results.qza\").view(OrdinationResults),\n",
        "    \"Unweighted Unifrac\": Artifact.load(\"core-metrics-results/unweighted_unifrac_pcoa_results.qza\").view(OrdinationResults),\n",
        "}\n",
        "\n",
        "metadata = pd.read_csv(\"metadata.tsv\", sep=\"\\t\", index_col=0)\n",
        "\n",
        "# Strip whitespace from all string/object columns\n",
        "for col_name in metadata.select_dtypes(include=['object']).columns:\n",
        "    metadata[col_name] = metadata[col_name].str.strip()\n",
        "n_pcs = 19\n",
        "\n",
        "comparisons = [\n",
        "    (\"Group\", None),\n",
        "    (\"Butyrate\", None),\n",
        "    (\"Disease\", None)\n",
        "]\n",
        "\n",
        "output_dir = \"beta_diversity_plots\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for col, filter_values in comparisons:\n",
        "    if col not in metadata.columns:\n",
        "        print(f\"Warning: Column '{col}' not found in metadata. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for ax, (distance_metric, pcoa_res) in zip(axes, pcoa_results.items()):\n",
        "        coords = pcoa_res.samples\n",
        "        df = coords.merge(metadata, left_index=True, right_index=True)\n",
        "        df.rename(columns={i: f'PC{i+1}' for i in range(n_pcs)}, inplace=True)\n",
        "\n",
        "        # Filter if needed\n",
        "        df_subset = df.copy()\n",
        "        if filter_values is not None:\n",
        "            df_subset = df_subset[df_subset[col].isin(filter_values)]\n",
        "\n",
        "        if df_subset.empty:\n",
        "            print(f\"Warning: No data for {col} in {distance_metric}. Skipping plot.\")\n",
        "            ax.set_title(f\"{distance_metric} (no data)\")\n",
        "            ax.axis('off')\n",
        "            continue\n",
        "\n",
        "        # Ensure PC1 and PC2 exist\n",
        "        if \"PC1\" not in df_subset.columns or \"PC2\" not in df_subset.columns:\n",
        "            print(f\"Warning: PC1 or PC2 missing for {distance_metric}. Skipping.\")\n",
        "            ax.set_title(f\"{distance_metric} (no PC1/PC2)\")\n",
        "            ax.axis('off')\n",
        "            continue\n",
        "\n",
        "        unique_groups = df_subset[col].dropna().unique()\n",
        "        palette = sns.color_palette(n_colors=len(unique_groups))\n",
        "        group_to_color = dict(zip(unique_groups, palette))\n",
        "\n",
        "        # Scatter plot\n",
        "        sns.scatterplot(\n",
        "            x=\"PC1\",\n",
        "            y=\"PC2\",\n",
        "            hue=col if not df_subset[col].isnull().all() else None,\n",
        "            data=df_subset,\n",
        "            s=100,\n",
        "            alpha=0.8,\n",
        "            palette=group_to_color if not df_subset[col].isnull().all() else None,\n",
        "            ax=ax\n",
        "        )\n",
        "\n",
        "        # Draw ellipses\n",
        "        for group, data_subset in df_subset.groupby(col):\n",
        "            if len(data_subset) < 2:\n",
        "                continue\n",
        "            centroid_x = data_subset[\"PC1\"].mean()\n",
        "            centroid_y = data_subset[\"PC2\"].mean()\n",
        "            width = data_subset[\"PC1\"].std() * 2\n",
        "            height = data_subset[\"PC2\"].std() * 2\n",
        "            ellipse = Ellipse(\n",
        "                (centroid_x, centroid_y),\n",
        "                width=width, height=height,\n",
        "                edgecolor=group_to_color[group],\n",
        "                facecolor='none', lw=2, alpha=0.7\n",
        "            )\n",
        "            ax.add_patch(ellipse)\n",
        "            ax.scatter(centroid_x, centroid_y, marker='x', color='black', s=120, zorder=10)\n",
        "\n",
        "        ax.set_title(distance_metric)\n",
        "        ax.set_xlabel(\"PC1\")\n",
        "        ax.set_ylabel(\"PC2\")\n",
        "\n",
        "    # Combine legend outside grid\n",
        "    handles, labels = axes[0].get_legend_handles_labels()\n",
        "    if handles:\n",
        "        fig.legend(handles, labels, title=col, bbox_to_anchor=(1.05, 0.5), loc='center left')\n",
        "\n",
        "    subset_label = \"all\" if filter_values is None else \"_\".join(filter_values)\n",
        "    fig.suptitle(f\"PCoA comparison ({col} = {subset_label})\", fontsize=16)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 0.85, 0.95])\n",
        "\n",
        "    filename = f\"PCoA_comparison_{col}_{subset_label}.png\"\n",
        "    filepath = os.path.join(output_dir, filename)\n",
        "    plt.savefig(filepath, dpi=300)\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mExported qiime/rooted-tree.qza as NewickDirectoryFormat to directory exported/rooted-tree\u001b[0m\n",
            "\u001b[?25h\u001b[0m/home/patwuch/miniforge3/envs/qiime2-amplicon-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mExported qiime/taxonomy.qza as TSVTaxonomyDirectoryFormat to directory exported/taxonomy\u001b[0m\n",
            "\u001b[?25h\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Export rooted tree and taxonomy for use in R or other software\n",
        "!qiime tools export \\\n",
        "    --input-path \"qiime/rooted-tree.qza\" \\\n",
        "    --output-path \"exported/rooted-tree\"\n",
        "!qiime tools export \\\n",
        "    --input-path \"qiime/taxonomy.qza\" \\\n",
        "    --output-path \"exported/taxonomy\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88f87cd5",
      "metadata": {},
      "source": [
        "Section 5 we create the PERMANOVA and BETADISPER tables using a combination of python and R, as R creates more legible results than qiime in this case.\n",
        "\n",
        "!!! The R cell will not run if you do not run the below cell to initiate R magic first !!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "11e784bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext rpy2.ipython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1ef3b825",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mExported core-metrics-results/aitchison_distance_matrix.qza as DistanceMatrixDirectoryFormat to directory _tmp_export_aitchison\u001b[0m\n",
            "\u001b[?25h\u001b[0m/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mExported core-metrics-results/jaccard_distance_matrix.qza as DistanceMatrixDirectoryFormat to directory _tmp_export_jaccard\u001b[0m\n",
            "\u001b[?25h\u001b[0m/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mExported core-metrics-results/canberra_distance_matrix.qza as DistanceMatrixDirectoryFormat to directory _tmp_export_canberra\u001b[0m\n",
            "\u001b[?25h\u001b[0m/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mExported core-metrics-results/bray_curtis_distance_matrix.qza as DistanceMatrixDirectoryFormat to directory _tmp_export_bray_curtis\u001b[0m\n",
            "\u001b[?25h\u001b[0m"
          ]
        }
      ],
      "source": [
        "core_metrics_dir = \"core-metrics-results\"\n",
        "qza_files = [f for f in os.listdir(core_metrics_dir) if f.endswith(\"_distance_matrix.qza\")]\n",
        "\n",
        "distance_names = []\n",
        "distance_paths = []\n",
        "\n",
        "for qza in qza_files:\n",
        "    name = qza.replace(\"_distance_matrix.qza\", \"\")\n",
        "    out_path = os.path.join(\"exported\", f\"{name}_distance_matrix.tsv\")\n",
        "\n",
        "    # Make sure export dir exists\n",
        "    os.makedirs(\"exported\", exist_ok=True)\n",
        "\n",
        "    # Use a temp dir for the raw export\n",
        "    tmp_dir = f\"_tmp_export_{name}\"\n",
        "    os.makedirs(tmp_dir, exist_ok=True)\n",
        "\n",
        "    # Export with QIIME2\n",
        "    !qiime tools export --input-path \"{os.path.join(core_metrics_dir, qza)}\" --output-path \"{tmp_dir}\"\n",
        "\n",
        "    # Move the exported file\n",
        "    raw_exported = os.path.join(tmp_dir, \"distance-matrix.tsv\")\n",
        "    if os.path.exists(raw_exported):\n",
        "        shutil.move(raw_exported, out_path)\n",
        "\n",
        "    # Clean up temp dir\n",
        "    shutil.rmtree(tmp_dir)\n",
        "\n",
        "    distance_names.append(name)\n",
        "    distance_paths.append(out_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3f3d2a1c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ PERMANOVA and betadisper results written to permanova_permdisp_global_results.tsv\n"
          ]
        }
      ],
      "source": [
        "%%R -i distance_names -i distance_paths \n",
        "library(vegan)\n",
        "library(dplyr)\n",
        "library(tibble)\n",
        "\n",
        "# ------------------------------\n",
        "# 1. Define your distance matrices\n",
        "# ------------------------------\n",
        "# Example:\n",
        "# distance_names = c(\"bray\", \"jaccard\")\n",
        "# distance_paths = c(\"bray_dist.tsv\", \"jaccard_dist.tsv\")\n",
        "distance_files <- setNames(as.list(distance_paths), distance_names)\n",
        "\n",
        "# ------------------------------\n",
        "# 2. Define comparisons and allowed levels\n",
        "# ------------------------------\n",
        "comparisons <- list(\n",
        "  Group = \"Group\",\n",
        "  Butyrate = \"Butyrate\",\n",
        "  Disease = \"Disease\"\n",
        ")\n",
        "\n",
        "# Optional: restrict to allowed levels\n",
        "allowed_levels <- list(\n",
        "  Group = c(\"PD_O\", \"Sh_Or\", \"Sh_int\", \"PD_int\", \"PD_Sh\"),\n",
        "  Butyrate = c(\"OR\",\"INT\",\"NO\"),\n",
        "  Disease = c(\"Y\",\"N\")\n",
        ")\n",
        "\n",
        "# ------------------------------\n",
        "# 3. Load metadata\n",
        "# ------------------------------\n",
        "meta <- read.table(\"metadata.tsv\", header = TRUE, sep = \"\\t\", row.names = 1, check.names = FALSE)\n",
        "\n",
        "# Clean up potential whitespace\n",
        "rownames(meta) <- trimws(rownames(meta))\n",
        "\n",
        "# ------------------------------\n",
        "# 4. Helper function to load distance matrices\n",
        "# ------------------------------\n",
        "load_distance <- function(file) {\n",
        "  mat <- as.matrix(read.table(file, header = TRUE, row.names = 1, sep = \"\\t\", check.names = FALSE))\n",
        "  rownames(mat) <- trimws(rownames(mat))\n",
        "  colnames(mat) <- trimws(colnames(mat))\n",
        "  as.dist(mat)\n",
        "}\n",
        "\n",
        "# ------------------------------\n",
        "# 5. Run global PERMANOVA + betadisper safely\n",
        "# ------------------------------\n",
        "results <- list()\n",
        "\n",
        "for (dname in names(distance_files)) {\n",
        "  d <- load_distance(distance_files[[dname]])\n",
        "  \n",
        "  for (comp_name in names(comparisons)) {\n",
        "    col <- comparisons[[comp_name]]\n",
        "    \n",
        "    # Subset metadata to allowed levels\n",
        "    if (!is.null(allowed_levels[[comp_name]])) {\n",
        "      meta_sub <- meta[meta[[col]] %in% allowed_levels[[comp_name]], , drop = FALSE]\n",
        "    } else {\n",
        "      meta_sub <- meta\n",
        "    }\n",
        "    \n",
        "    # Drop NA values\n",
        "    meta_sub <- meta_sub[!is.na(meta_sub[[col]]), , drop = FALSE]\n",
        "    \n",
        "    # Match samples between metadata and distance\n",
        "    common_samples <- intersect(rownames(meta_sub), labels(d))\n",
        "    if (length(common_samples) < 2) next\n",
        "    \n",
        "    meta_sub <- meta_sub[common_samples, , drop = FALSE]\n",
        "    d_sub <- as.dist(as.matrix(d)[common_samples, common_samples])\n",
        "    \n",
        "    # Skip if fewer than 2 levels remain\n",
        "    if (length(unique(meta_sub[[col]])) < 2) next\n",
        "    \n",
        "    # ---- Global PERMANOVA ----\n",
        "    fmla <- as.formula(paste(\"d_sub ~\", col))\n",
        "    ad_global <- tryCatch(\n",
        "      adonis2(fmla, data = meta_sub, permutations = 9999),\n",
        "      error = function(e) NULL\n",
        "    )\n",
        "    \n",
        "    if (!is.null(ad_global)) {\n",
        "      ad_row <- as.data.frame(ad_global[1, ])\n",
        "      ad_row <- rownames_to_column(ad_row, \"Term\")\n",
        "      ad_row$distance <- dname\n",
        "      ad_row$comparison <- comp_name\n",
        "      ad_row$scope <- \"global\"\n",
        "      ad_row$pair <- NA\n",
        "      ad_row$test <- \"permanova\"\n",
        "      results[[length(results) + 1]] <- ad_row\n",
        "    }\n",
        "    \n",
        "    # ---- Global betadisper ----\n",
        "    bd_global <- tryCatch(betadisper(d_sub, meta_sub[[col]]), error = function(e) NULL)\n",
        "    \n",
        "    if (!is.null(bd_global)) {\n",
        "      bd_global_anova <- anova(bd_global)\n",
        "      bd_row <- as.data.frame(bd_global_anova[1, ])\n",
        "      bd_row <- rownames_to_column(bd_row, \"Term\")\n",
        "      bd_row$distance <- dname\n",
        "      bd_row$comparison <- comp_name\n",
        "      bd_row$scope <- \"global\"\n",
        "      bd_row$pair <- NA\n",
        "      bd_row$test <- \"betadisper\"\n",
        "      results[[length(results) + 1]] <- bd_row\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "# ------------------------------\n",
        "# 6. Combine and save results\n",
        "# ------------------------------\n",
        "if (length(results) > 0) {\n",
        "  permanova_permdisp_results <- bind_rows(results) %>%\n",
        "    select(distance, comparison, scope, pair, test, everything())\n",
        "  \n",
        "  write.table(\n",
        "    permanova_permdisp_results,\n",
        "    file = \"permanova_permdisp_global_results.tsv\",\n",
        "    sep = \"\\t\",\n",
        "    quote = FALSE,\n",
        "    row.names = FALSE\n",
        "  )\n",
        "  \n",
        "  cat(\"‚úÖ PERMANOVA and betadisper results written to permanova_permdisp_global_results.tsv\\n\")\n",
        "} else {\n",
        "  cat(\"‚ö†Ô∏è No valid comparisons were found (possibly due to filtering or missing levels).\\n\")\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c75afb4",
      "metadata": {},
      "source": [
        "Section 6 to evaluate differential taxa, we use either ANCOMBC or ANCOMBC2.\n",
        "If you want to get full results and static plots, follow the ANCOMBC2 route.\n",
        "If you want to get easy visualisation for Qiime2 View, use the ANCOMBC approach.\n",
        "Either way they should yield similar results so long as your parameters remain consistent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e64188aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ANCOMBC approach\n",
        "# -------------------------------\n",
        "# 1. Compare all 6 groups (Group)\n",
        "# -------------------------------\n",
        "!qiime composition ancombc \\\n",
        "  --i-table \"qiime/table.qza\" \\\n",
        "  --m-metadata-file \"metadata.tsv\" \\\n",
        "  --p-formula Group \\\n",
        "  --o-differentials \"qiime/ancombc-Group-results.qza\"\n",
        "\n",
        "!qiime composition da-barplot \\\n",
        "  --i-data \"qiime/ancombc-Group-results.qza\" \\\n",
        "  --p-significance-threshold 0.001 \\\n",
        "  --o-visualization \"qiime/ancombc-Group-results.qzv\"\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Compare all 6 groups focusing on MainType (E vs C)\n",
        "# -------------------------------\n",
        "!qiime composition ancombc \\\n",
        "  --i-table \"qiime/table.qza\" \\\n",
        "  --m-metadata-file \"metadata.tsv\" \\\n",
        "  --p-formula MainType \\\n",
        "  --o-differentials \"qiime/ancombc-E-vs-C-results.qza\"\n",
        "\n",
        "!qiime composition da-barplot \\\n",
        "  --i-data \"qiime/ancombc-E-vs-C-results.qza\" \\\n",
        "  --p-significance-threshold 0.001 \\\n",
        "  --o-visualization \"qiime/ancombc-E-vs-C-results.qzv\"\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Compare Modifier within MainType E\n",
        "# -------------------------------\n",
        "!qiime feature-table filter-samples \\\n",
        "  --i-table \"qiime/table.qza\" \\\n",
        "  --m-metadata-file \"metadata.tsv\" \\\n",
        "  --p-where \"MainType='E'\" \\\n",
        "  --o-filtered-table \"qiime/table-E.qza\"\n",
        "\n",
        "!qiime composition ancombc \\\n",
        "  --i-table \"qiime/table-E.qza\" \\\n",
        "  --m-metadata-file \"metadata.tsv\" \\\n",
        "  --p-formula Modifier \\\n",
        "  --o-differentials \"qiime/ancombc-E-Modifier-results.qza\"\n",
        "\n",
        "!qiime composition da-barplot \\\n",
        "  --i-data \"qiime/ancombc-E-Modifier-results.qza\" \\\n",
        "  --p-significance-threshold 0.001 \\\n",
        "  --o-visualization \"qiime/ancombc-E-Modifier-results.qzv\"\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Compare Modifier within MainType C\n",
        "# -------------------------------\n",
        "!qiime feature-table filter-samples \\\n",
        "  --i-table \"qiime/table.qza\" \\\n",
        "  --m-metadata-file \"metadata.tsv\" \\\n",
        "  --p-where \"MainType='C'\" \\\n",
        "  --o-filtered-table \"qiime/table-C.qza\"\n",
        "\n",
        "!qiime composition ancombc \\\n",
        "  --i-table \"qiime/table-C.qza\" \\\n",
        "  --m-metadata-file \"metadata.tsv\" \\\n",
        "  --p-formula Modifier \\\n",
        "  --o-differentials \"qiime/ancombc-C-Modifier-results.qza\"\n",
        "\n",
        "!qiime composition da-barplot \\\n",
        "  --i-data \"qiime/ancombc-C-Modifier-results.qza\" \\\n",
        "  --p-significance-threshold 0.001 \\\n",
        "  --o-visualization \"qiime/ancombc-C-Modifier-results.qzv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4275f39f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/patwuch/miniforge3/envs/qiime2-2025.7/lib/python3.10/site-packages/emperor/__init__.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32mSaved FeatureData[ANCOMBC2Output] to: qiime/ancombc2-Group-results.qza\u001b[0m\n",
            "\u001b[?25h\u001b[0m"
          ]
        }
      ],
      "source": [
        "# -------------------------------\n",
        "# ANCOMBC2 APPROACH\n",
        "# -------------------------------\n",
        "# 1. Compare all 6 groups (Group)\n",
        "# Note ancombc2 automatically uses a ONE vs. REST approach for differential analysis\n",
        "# -------------------------------\n",
        "!qiime composition ancombc2 \\\n",
        "  --i-table \"qiime/table.qza\" \\\n",
        "  --m-metadata-file \"metadata.tsv\" \\\n",
        "  --p-fixed-effects-formula Group \\\n",
        "  --o-ancombc2-output \"qiime/ancombc2-Group-results.qza\"\n",
        "\n",
        "\n",
        "# # -------------------------------\n",
        "# # 2. Compare all 6 groups focusing on MainType (E vs C)\n",
        "# # -------------------------------\n",
        "# !qiime composition ancombc2 \\\n",
        "#   --i-table \"qiime/table.qza\" \\\n",
        "#   --m-metadata-file \"metadata.tsv\" \\\n",
        "#   --p-fixed-effects-formula MainType \\\n",
        "#   --o-ancombc2-output \"qiime/ancombc2-E-vs-C-results.qza\"\n",
        "\n",
        "\n",
        "# # -------------------------------\n",
        "# # 3. Compare Modifier within MainType E\n",
        "# # -------------------------------\n",
        "# !qiime feature-table filter-samples \\\n",
        "#   --i-table \"qiime/table.qza\" \\\n",
        "#   --m-metadata-file \"metadata.tsv\" \\\n",
        "#   --p-where \"MainType='E'\" \\\n",
        "#   --o-filtered-table \"qiime/table-E.qza\"\n",
        "\n",
        "# !qiime composition ancombc2 \\\n",
        "#   --i-table \"qiime/table-E.qza\" \\\n",
        "#   --m-metadata-file \"metadata.tsv\" \\\n",
        "#   --p-fixed-effects-formula Modifier \\\n",
        "#   --o-ancombc2-output \"qiime/ancombc2-E-Modifier-results.qza\"\n",
        "\n",
        "\n",
        "# # -------------------------------\n",
        "# # 4. Compare Modifier within MainType C\n",
        "# # -------------------------------\n",
        "# !qiime feature-table filter-samples \\\n",
        "#   --i-table \"qiime/table.qza\" \\\n",
        "#   --m-metadata-file \"metadata.tsv\" \\\n",
        "#   --p-where \"MainType='C'\" \\\n",
        "#   --o-filtered-table \"qiime/table-C.qza\"\n",
        "\n",
        "# !qiime composition ancombc2 \\\n",
        "#   --i-table \"qiime/table-C.qza\" \\\n",
        "#   --m-metadata-file \"metadata.tsv\" \\\n",
        "#   --p-fixed-effects-formula Modifier \\\n",
        "#   --o-ancombc2-output \"qiime/ancombc2-C-Modifier-results.qza\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42a74a0e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# To create static plots we have to export the ancombc2 artefacts to jsonl files\n",
        "!qiime tools export \\\n",
        "  --input-path qiime/ancombc2-Group-results.qza \\\n",
        "  --output-path exported/ancombc2-Group-results\n",
        "\n",
        "!qiime tools export \\\n",
        "  --input-path qiime/ancombc2-E-vs-C-results.qza \\\n",
        "  --output-path exported/ancombc2-E-vs-C-results\n",
        "\n",
        "!qiime tools export \\\n",
        "  --input-path qiime/ancombc2-E-Modifier-results.qza \\\n",
        "  --output-path exported/ancombc2-E-Modifier-results\n",
        "\n",
        "!qiime tools export \\\n",
        "  --input-path qiime/ancombc2-C-Modifier-results.qza \\\n",
        "  --output-path exported/ancombc2-C-Modifier-results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48f7b580",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# --- DIRECTORIES TO PROCESS ---\n",
        "# List all your exported ANCOM-BC2 result directories\n",
        "EXPORTED_FOLDERS = [\n",
        "    'exported/ancombc2-Group-results',\n",
        "    'exported/ancombc2-E-vs-C-results',\n",
        "    'exported/ancombc2-E-Modifier-results',\n",
        "    'exported/ancombc2-C-Modifier-results'\n",
        "]\n",
        "# ------------------------------\n",
        "def jsonl_to_tsv(input_filename, output_filename):\n",
        "    \"\"\"\n",
        "    Parses a specific JSONL format (with a schema header) and converts it to TSV.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(input_filename, 'r', encoding='utf-8') as infile:\n",
        "            # 1. Read the schema line (first line)\n",
        "            schema_line = infile.readline()\n",
        "            if not schema_line:\n",
        "                print(\"Error: Input file is empty.\")\n",
        "                return\n",
        "\n",
        "            schema = json.loads(schema_line)\n",
        "            \n",
        "            # Extract the header/field names from the 'fields' array\n",
        "            # This ensures the correct order for the TSV output\n",
        "            header = [field['name'] for field in schema.get('fields', [])]\n",
        "\n",
        "            if not header:\n",
        "                print(\"Error: Could not extract header from the schema.\")\n",
        "                return\n",
        "\n",
        "            # 2. Open the output file for writing TSV\n",
        "            with open(output_filename, 'w', newline='', encoding='utf-8') as outfile:\n",
        "                # Use the csv module with the tab character ('\\t') as the delimiter\n",
        "                writer = csv.writer(outfile, delimiter='\\t')\n",
        "                \n",
        "                # Write the header row\n",
        "                writer.writerow(header)\n",
        "                \n",
        "                # 3. Process the remaining data lines\n",
        "                for line in infile:\n",
        "                    if not line.strip(): # Skip empty lines\n",
        "                        continue\n",
        "                        \n",
        "                    try:\n",
        "                        data_record = json.loads(line)\n",
        "                        \n",
        "                        # Extract values in the order defined by the header\n",
        "                        row_data = [data_record.get(field_name, '') for field_name in header]\n",
        "                        \n",
        "                        # Write the data row\n",
        "                        writer.writerow(row_data)\n",
        "                        \n",
        "                    except json.JSONDecodeError as e:\n",
        "                        print(f\"Skipping malformed JSON line: {line.strip()}. Error: {e}\", file=sys.stderr)\n",
        "                        continue\n",
        "                        \n",
        "        print(f\"Successfully converted {input_filename} to {output_filename}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{input_filename}' was not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        \n",
        "# Run the conversion for all specified directories\n",
        "for folder in EXPORTED_FOLDERS:\n",
        "    # Check if the directory exists before trying to convert\n",
        "    if os.path.isdir(folder):\n",
        "        print(f\"Processing folder: {folder}\")\n",
        "        \n",
        "        # Use glob to find all files ending with .jsonl in the current folder\n",
        "        # The ** is for recursive searching (optional, but good practice if needed)\n",
        "        jsonl_files = glob.glob(os.path.join(folder, '*.jsonl'))\n",
        "\n",
        "        if not jsonl_files:\n",
        "            print(f\"No .jsonl files found in '{folder}'.\")\n",
        "\n",
        "        for input_file in jsonl_files:\n",
        "            # 1. Get the base filename (e.g., 'data_01') without the extension\n",
        "            base_name = os.path.splitext(os.path.basename(input_file))[0]\n",
        "            \n",
        "            # 2. Construct the output TSV filename\n",
        "            # The output file will be placed in the same directory as the input file\n",
        "            output_file = os.path.join(folder, f\"{base_name}.tsv\")\n",
        "            \n",
        "            # 3. Run the conversion function\n",
        "            print(f\"  Converting '{os.path.basename(input_file)}' to '{os.path.basename(output_file)}'...\")\n",
        "            jsonl_to_tsv(input_file, output_file)\n",
        "            \n",
        "    else:\n",
        "        print(f\"Folder not found: '{folder}'. Please check your path.\")\n",
        "\n",
        "print(\"\\n JSONL to .tsv conversion complete. \")\n",
        "print(\"\\n Combining all .tsv files...\")\n",
        "\n",
        "# Column names you expect in each folder (change if yours are named differently)\n",
        "EXPECTED_FILES = [\"diff.tsv\", \"lfc.tsv\", \"p.tsv\", \"q.tsv\", \"se.tsv\", \"W.tsv\", \"passed_ss.tsv\"]\n",
        "\n",
        "for folder in EXPORTED_FOLDERS:\n",
        "    if not os.path.isdir(folder):\n",
        "        print(f\" Folder not found: {folder}\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\n Processing folder: {folder}\")\n",
        "\n",
        "    dfs = {}  # dictionary to store all loaded TSVs\n",
        "    for fname in EXPECTED_FILES:\n",
        "        file_path = os.path.join(folder, fname)\n",
        "        if os.path.exists(file_path):\n",
        "            print(f\"   Found: {fname}\")\n",
        "            dfs[fname.replace(\".tsv\", \"\")] = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
        "        else:\n",
        "            print(f\"   Missing: {fname}\")\n",
        "\n",
        "    if not dfs:\n",
        "        print(\"   No TSV files found ‚Äî skipping this folder.\")\n",
        "        continue\n",
        "\n",
        "    # Combine all TSVs into one DataFrame\n",
        "    combined = pd.concat(dfs, axis=1)\n",
        "\n",
        "    # Optional: flatten multi-index columns (e.g., diff:ComparisonA)\n",
        "    combined.columns = [f\"{stat}:{col}\" for stat, col in combined.columns]\n",
        "\n",
        "    # Save the final combined file\n",
        "    output_path = os.path.join(folder, \"ancombc2_combined.tsv\")\n",
        "    combined.to_csv(output_path, sep=\"\\t\")\n",
        "    print(f\"   Combined table saved: {output_path}\")\n",
        "\n",
        "print(\"\\n All comparison sets processed. \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f872956e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----------------- CONFIG -----------------\n",
        "EXPORTED_FOLDERS = [\n",
        "    'exported/ancombc2-Group-results',\n",
        "    'exported/ancombc2-E-vs-C-results',\n",
        "    'exported/ancombc2-E-Modifier-results',\n",
        "    'exported/ancombc2-C-Modifier-results'\n",
        "]\n",
        "\n",
        "OUTPUT_DIR = \"differentials_histograms_barplots\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# ----------------- LOAD TAXONOMY -----------------\n",
        "tax_df = pd.read_csv(\"exported/exported-taxonomy/taxonomy.tsv\", sep=\"\\t\", index_col=0)  # index is Feature ID\n",
        "\n",
        "# ----------------- LOOP THROUGH COMPARISONS -----------------\n",
        "for folder in EXPORTED_FOLDERS:\n",
        "    comparison_name = os.path.basename(folder).replace(\"ancombc2-\", \"\").replace(\"-results\", \"\")\n",
        "    print(f\"\\nüìä Processing {comparison_name}\")\n",
        "\n",
        "    combined_path = os.path.join(folder, \"ancombc2_combined.tsv\")\n",
        "    if not os.path.exists(combined_path):\n",
        "        print(f\"‚ùå Missing {combined_path}, skipping.\")\n",
        "        continue\n",
        "\n",
        "    df = pd.read_csv(combined_path, sep=\"\\t\", index_col=0)\n",
        "\n",
        "    # --- Map Feature IDs to readable taxa names ---\n",
        "    df[\"Taxon\"] = df.index.map(lambda x: tax_df.loc[x, \"Taxon\"] if x in tax_df.index else \"Unassigned\")\n",
        "\n",
        "    # --- Find q-value columns ---\n",
        "    q_cols = [c for c in df.columns if c.startswith(\"q:\")]\n",
        "\n",
        "    # --- Combined q-value histograms ---\n",
        "    thresholds = [0.05, 0.1, 0.2]\n",
        "    if q_cols:\n",
        "        max_cols = 3\n",
        "        n_q = len(q_cols)\n",
        "        n_rows = (n_q + max_cols - 1) // max_cols\n",
        "        n_cols = min(n_q, max_cols)\n",
        "\n",
        "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(6*n_cols, 4*n_rows), squeeze=False)\n",
        "\n",
        "        for i, q_col in enumerate(q_cols):\n",
        "            row = i // max_cols\n",
        "            col = i % max_cols\n",
        "            ax = axes[row, col]\n",
        "\n",
        "            for t in thresholds:\n",
        "                sig_count = (df[q_col] < t).sum()\n",
        "                print(f\"  {q_col}: q < {t:.2f}: {sig_count} taxa\")\n",
        "\n",
        "            sns.histplot(df[q_col].dropna(), bins=40, kde=False, ax=ax)\n",
        "            ax.axvline(0.05, color=\"red\", linestyle=\"--\", label=\"0.05\")\n",
        "            ax.axvline(0.1, color=\"orange\", linestyle=\"--\", label=\"0.10\")\n",
        "            ax.axvline(0.2, color=\"green\", linestyle=\"--\", label=\"0.20\")\n",
        "            ax.set_title(f\"{q_col}\")\n",
        "            ax.set_xlabel(\"q-value\")\n",
        "            ax.set_ylabel(\"Count\")\n",
        "            ax.legend()\n",
        "\n",
        "        # Turn off empty subplots\n",
        "        total_plots = n_rows * n_cols\n",
        "        if total_plots > n_q:\n",
        "            for j in range(n_q, total_plots):\n",
        "                row = j // max_cols\n",
        "                col = j % max_cols\n",
        "                axes[row, col].axis(\"off\")\n",
        "\n",
        "        plt.suptitle(f\"Q-value distributions - {comparison_name}\")\n",
        "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "        plt.savefig(os.path.join(OUTPUT_DIR, f\"{comparison_name}_qval_hist_combined.png\"), dpi=300)\n",
        "        plt.close()\n",
        "        print(f\"‚úÖ Combined Q-value histogram saved: {comparison_name}_qval_hist_combined.png\")\n",
        "\n",
        "    # --- Identify relevant columns for barplot ---\n",
        "    lfc_cols = [c for c in df.columns if c.startswith(\"lfc:\")]\n",
        "    se_cols = [c for c in df.columns if c.startswith(\"se:\")]\n",
        "    import textwrap\n",
        "    # --- Build barplot data ---\n",
        "    barplot_data = []\n",
        "    for lfc_col in lfc_cols:\n",
        "        comparison = lfc_col.replace(\"lfc:\", \"\")\n",
        "        se_col = f\"se:{comparison}\"\n",
        "        q_col = f\"q:{comparison}\"\n",
        "\n",
        "        lfc = df[lfc_col]\n",
        "        se = df[se_col] if se_col in df.columns else pd.Series([None]*len(df), index=df.index)\n",
        "        q = df[q_col] if q_col in df.columns else pd.Series([1.0]*len(df), index=df.index)\n",
        "\n",
        "        sig = q < 0.1\n",
        "        for idx in df.index[sig]:\n",
        "            barplot_data.append({\n",
        "                \"Taxon\": df.loc[idx, \"Taxon\"],  # readable taxon name\n",
        "                \"Comparison\": comparison,\n",
        "                \"lfc\": lfc.loc[idx],\n",
        "                \"se\": se.loc[idx],\n",
        "                \"q\": q.loc[idx]\n",
        "            })\n",
        "\n",
        "    barplot_df = pd.DataFrame(barplot_data)\n",
        "\n",
        "    if not barplot_df.empty:\n",
        "        # Wrap long taxa names at 20 characters\n",
        "        barplot_df[\"Taxon_wrapped\"] = barplot_df[\"Taxon\"].apply(lambda x: \"\\n\".join(textwrap.wrap(x, 20)))\n",
        "\n",
        "        # Adjust figure width based on number of unique taxa\n",
        "        fig_width = max(12, len(barplot_df[\"Taxon\"].unique()) * 0.6)\n",
        "        plt.figure(figsize=(fig_width, 6))\n",
        "\n",
        "        # Create the barplot and get axes object\n",
        "        ax = sns.barplot(\n",
        "            data=barplot_df,\n",
        "            x=\"Taxon_wrapped\", y=\"lfc\", hue=\"Comparison\",\n",
        "            dodge=True, palette=\"coolwarm\", errorbar=None\n",
        "        )\n",
        "\n",
        "        # Add error bars correctly for each bar\n",
        "        for i, row in barplot_df.iterrows():\n",
        "            if pd.notna(row[\"se\"]):\n",
        "                # Find the center x-position of the corresponding bar\n",
        "                bars = [b for b in ax.patches if b.get_height() == row[\"lfc\"] and b.get_x() >= 0]\n",
        "                if bars:\n",
        "                    bar = bars[0]  # take first matching bar\n",
        "                    height = bar.get_height()\n",
        "                    ax.errorbar(\n",
        "                        bar.get_x() + bar.get_width() / 2,  # center of bar\n",
        "                        height,\n",
        "                        yerr=row[\"se\"],\n",
        "                        fmt='none', c='black', capsize=3\n",
        "                    )\n",
        "\n",
        "        plt.xticks(rotation=80, ha=\"right\")\n",
        "        plt.ylabel(\"Log fold change (lfc)\")\n",
        "        plt.title(f\"Differential taxa barplot - {comparison_name} (q < 0.1)\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(OUTPUT_DIR, f\"{comparison_name}_barplot.png\"), dpi=300)\n",
        "        plt.close()\n",
        "        print(f\"‚úÖ Barplot saved for {comparison_name}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No significant taxa for barplot (q < 0.1).\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nüéâ Finished! Results in:\", OUTPUT_DIR)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "q2-amplicon-core-2025.10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
